{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff41b844-9241-4515-8516-e241350bde43",
   "metadata": {},
   "source": [
    "# Check Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d19eafbd-0d7e-4398-8172-5d62b4b0a116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "am I in Colab? False\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  import google.colab\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "print(f\"am I in Colab? {IN_COLAB}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361beb50-4fff-464d-845e-312288293d98",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5a6ca2c-a286-475a-b37a-a97c8c95b2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import random\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm \n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import uuid\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdf3466-2318-4f6a-99a8-a07c0d1ee122",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33e52a39-0166-4f7a-a292-e8c8cdb5852d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "  # Colab\n",
    "  BASE_DIR = \".\"\n",
    "  BACKUPS_DATA_DIR   = \"/content/drive/MyDrive/Colab Notebooks/Dataclub/llm/data\"\n",
    "else:\n",
    "  # Local\n",
    "  BASE_DIR = \"..\"\n",
    "  BACKUPS_DATA_DIR   = \"../backups\"\n",
    "\n",
    "# Raw directory\n",
    "RAW_DATA_DIR               = f\"{BASE_DIR}/data/raw\"\n",
    "RAW_DOCS_DATA_DIR          = f\"{BASE_DIR}/data/raw/documents\"\n",
    "RAW_INFO_DATA_DIR          = f\"{BASE_DIR}/data/raw/info\"\n",
    "# Preprocessing\n",
    "PROCESSED_DATA_DIR         = f\"{BASE_DIR}/data/processed\"\n",
    "PROCESSED_DOCS_DATA_DIR    = f\"{BASE_DIR}/data/processed/documents\"\n",
    "# Indexing\n",
    "INDEXING_DATA_DIR          = f\"{BASE_DIR}/data/indexing\"\n",
    "INDEXING_DOCS_DATA_DIR     = f\"{BASE_DIR}/data/indexing/documents\"\n",
    "# Test directory\n",
    "TEST_DATA_DIR               = f\"{BASE_DIR}/data/test\"\n",
    "GROUND_TRUTH_DATA_DIR       = f\"{BASE_DIR}/data/test/ground_truth\"\n",
    "GROUND_TRUTH_DOCS_DATA_DIR  = f\"{BASE_DIR}/data/test/ground_truth/documents\"\n",
    "GROUND_TRUTH_GEN_DATA_DIR   = f\"{BASE_DIR}/data/test/ground_truth/generated\"\n",
    "# Test directory\n",
    "EVAL_DATA_DIR            = f\"{BASE_DIR}/data/evaluation\"\n",
    "EVAL_RETRIEVER_DATA_DIR  = f\"{BASE_DIR}/data/evaluation/retriever\"\n",
    "EVAL_RAG_DATA_DIR        = f\"{BASE_DIR}/data/evaluation/rag\"\n",
    "# Config Prompts Dir\n",
    "PROMPTS_CONFIG_DIR = f\"{BASE_DIR}/cooking_recipe_assistant/config/prompts\"\n",
    "\n",
    "# Raw Info\n",
    "PLAYLIST_INFO_PATH = f\"{RAW_INFO_DATA_DIR}/playlist_info.pkl\"\n",
    "VIDEO_PLAYLIST_MAP_PATH = f\"{RAW_INFO_DATA_DIR}/video_playlist_map.pkl\"\n",
    "\n",
    "# Ground-truth\n",
    "GROUND_TRUTH_PATH = f\"{GROUND_TRUTH_DATA_DIR}/ground-truth-retrieval.csv\"\n",
    "\n",
    "# Optimization\n",
    "REST_OPT_ES_BM25_PATH       = f\"{EVAL_RETRIEVER_DATA_DIR}/res-opt-es-bm25.json\"\n",
    "REST_OPT_ES_HYBRID_PATH     = f\"{EVAL_RETRIEVER_DATA_DIR}/res-opt-es-hybrid.json\"\n",
    "REST_OPT_ES_HYBRID_RRF_PATH = f\"{EVAL_RETRIEVER_DATA_DIR}/res-opt-es-hybrid-rrf.json\"\n",
    "\n",
    "# Make dirs if not exists\n",
    "if not os.path.exists(RAW_DATA_DIR):\n",
    "  print(\"Not exists dir: \", RAW_DATA_DIR)\n",
    "os.makedirs(RAW_DOCS_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(RAW_INFO_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(PROCESSED_DOCS_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(TEST_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(EVAL_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(BACKUPS_DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "001d97e8-b2bf-4e55-9bf5-9a494f171c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Agregar solo si no está ya en sys.path\n",
    "if BASE_DIR not in sys.path:\n",
    "    sys.path.append(BASE_DIR)\n",
    "\n",
    "# Ahora puedes importar tu módulo\n",
    "import cooking_recipe_assistant\n",
    "from cooking_recipe_assistant.commons.utils import (\n",
    "    read_pickle, \n",
    "    read_document, \n",
    "    read_text,\n",
    "    save_pickle, \n",
    "    save_document,\n",
    "    save_text\n",
    ")\n",
    "\n",
    "from cooking_recipe_assistant.evaluation.retrievers import evaluate\n",
    "from cooking_recipe_assistant.evaluation.optimization import run_hyperopt\n",
    "from cooking_recipe_assistant.rags.retrievers.es_bm25 import es_bm25_query\n",
    "from cooking_recipe_assistant.rags.retrievers.es_hybrid import es_hybrid_query\n",
    "from cooking_recipe_assistant.rags.retrievers.es_hybrid_rrf import es_hybrid_rrf_query\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3f5ead1-e217-4f5e-8ca3-ae6fe233d19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listar todas las variables de entorno\n",
    "#for key, value in os.environ.items():\n",
    "#    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acfca201-eb10-4e8a-a95b-d4e1ca6bdc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_grafana_data(df):\n",
    "    options = [\"+1 (Positive)\", \"-1 (Negative)\", \"Pass (Skip feedback)\"]\n",
    "    random.seed(42)\n",
    "    for index, answer_data in df.iterrows():\n",
    "        conversation_id = str(uuid.uuid4())\n",
    "        question = answer_data['question']\n",
    "        answer_data.pop('question')\n",
    "        #print(row)\n",
    "        db.save_conversation(\n",
    "            conversation_id=conversation_id,\n",
    "            question=question,\n",
    "            answer_data=answer_data,\n",
    "        )\n",
    "        feedback = random.choice(options)\n",
    "        #print(feedback) \n",
    "        if feedback != \"Pass (Skip feedback)\":\n",
    "            feedback_value = 1 if feedback == \"+1 (Positive)\" else -1\n",
    "            #print(feedback_value) \n",
    "            db.save_feedback(\n",
    "                conversation_id=conversation_id,\n",
    "                feedback=feedback_value\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834d7833-f84d-4850-806d-d6915be415d6",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a175f315-ef54-4e38-94c8-cc6056b2b6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"POSTGRES_HOST\"] = \"localhost\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1f6d1e9-5ffe-443b-a08b-27921bdb33e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "363a3568-65f4-416a-8002-3272d83965f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database timezone: Etc/UTC\n",
      "Database current time (UTC): 2024-10-28 21:10:16.344565+00:00\n",
      "Database current time (Europe/Berlin): 2024-10-28 22:10:16.344565+01:00\n",
      "Python current time: 2024-10-28 22:10:16.345986+01:00\n",
      "Inserted time (UTC): 2024-10-28 21:10:16.345986+00:00\n",
      "Inserted time (Europe/Berlin): 2024-10-28 22:10:16.345986+01:00\n",
      "Selected time (UTC): 2024-10-28 21:10:16.345986+00:00\n",
      "Selected time (Europe/Berlin): 2024-10-28 22:10:16.345986+01:00\n"
     ]
    }
   ],
   "source": [
    "from cooking_recipe_assistant.database import db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36b508c-6772-4df0-bf95-a8be55e8dfa7",
   "metadata": {},
   "source": [
    "## gpt-4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0481b3c-aa1d-4a8c-8c07-0fa1afc46cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-4o-mini'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_4O_MINI_MODEL_NAME = 'gpt-4o-mini'\n",
    "GPT_4O_MINI_MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "635e47e2-6abc-410a-a812-22374d07dcdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/evaluation/rag'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EVAL_RAG_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "222c3fc5-7add-4234-820a-0a9b042b9b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_RAG_GPT_4O_MINI_HYBRID_DATA_DIR = f\"{EVAL_RAG_DATA_DIR}/{GPT_4O_MINI_MODEL_NAME}_hybrid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33061f19-ae62-4357-aada-0c3b4e507b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_rag_hybrid_gpt_4o_mini_stats = pd.read_csv(\n",
    "    f\"{EVAL_RAG_GPT_4O_MINI_HYBRID_DATA_DIR}/rag-evaluation-stats.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4739845-d937-4bba-8821-1cae4315eadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>model_used</th>\n",
       "      <th>response_time</th>\n",
       "      <th>relevance</th>\n",
       "      <th>relevance_explanation</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>eval_prompt_tokens</th>\n",
       "      <th>eval_completion_tokens</th>\n",
       "      <th>eval_total_tokens</th>\n",
       "      <th>openai_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the recommended temperature and time t...</td>\n",
       "      <td>The recommended temperature to bake the rolled...</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>1.349952</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer provides the exact temper...</td>\n",
       "      <td>2254</td>\n",
       "      <td>43</td>\n",
       "      <td>2297</td>\n",
       "      <td>258</td>\n",
       "      <td>47</td>\n",
       "      <td>305</td>\n",
       "      <td>0.000431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What's the best way to achieve a slightly liqu...</td>\n",
       "      <td>To achieve a slightly liquid consistency for t...</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>1.939975</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "      <td>2267</td>\n",
       "      <td>78</td>\n",
       "      <td>2345</td>\n",
       "      <td>288</td>\n",
       "      <td>58</td>\n",
       "      <td>346</td>\n",
       "      <td>0.000465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can I adjust the cooking time of the millefeui...</td>\n",
       "      <td>The cooking time for the Eggplant, Tomato, and...</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>2.055440</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "      <td>2178</td>\n",
       "      <td>79</td>\n",
       "      <td>2257</td>\n",
       "      <td>294</td>\n",
       "      <td>49</td>\n",
       "      <td>343</td>\n",
       "      <td>0.000448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do I grease the mold for the Creamy Fried ...</td>\n",
       "      <td>To grease the mold for the Creamy Fried Milk d...</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>1.479998</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "      <td>1972</td>\n",
       "      <td>59</td>\n",
       "      <td>2031</td>\n",
       "      <td>270</td>\n",
       "      <td>52</td>\n",
       "      <td>322</td>\n",
       "      <td>0.000403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the ideal temperature and timing to ch...</td>\n",
       "      <td>The filled chicken in the Chicken Villaray rec...</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>1.629993</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer provides both the timing ...</td>\n",
       "      <td>1971</td>\n",
       "      <td>56</td>\n",
       "      <td>2027</td>\n",
       "      <td>262</td>\n",
       "      <td>60</td>\n",
       "      <td>322</td>\n",
       "      <td>0.000405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the recommended temperature and time t...   \n",
       "1  What's the best way to achieve a slightly liqu...   \n",
       "2  Can I adjust the cooking time of the millefeui...   \n",
       "3  How do I grease the mold for the Creamy Fried ...   \n",
       "4  What is the ideal temperature and timing to ch...   \n",
       "\n",
       "                                              answer   model_used  \\\n",
       "0  The recommended temperature to bake the rolled...  gpt-4o-mini   \n",
       "1  To achieve a slightly liquid consistency for t...  gpt-4o-mini   \n",
       "2  The cooking time for the Eggplant, Tomato, and...  gpt-4o-mini   \n",
       "3  To grease the mold for the Creamy Fried Milk d...  gpt-4o-mini   \n",
       "4  The filled chicken in the Chicken Villaray rec...  gpt-4o-mini   \n",
       "\n",
       "   response_time relevance                              relevance_explanation  \\\n",
       "0       1.349952  RELEVANT  The generated answer provides the exact temper...   \n",
       "1       1.939975  RELEVANT  The generated answer directly addresses the qu...   \n",
       "2       2.055440  RELEVANT  The generated answer directly addresses the qu...   \n",
       "3       1.479998  RELEVANT  The generated answer directly addresses the qu...   \n",
       "4       1.629993  RELEVANT  The generated answer provides both the timing ...   \n",
       "\n",
       "   prompt_tokens  completion_tokens  total_tokens  eval_prompt_tokens  \\\n",
       "0           2254                 43          2297                 258   \n",
       "1           2267                 78          2345                 288   \n",
       "2           2178                 79          2257                 294   \n",
       "3           1972                 59          2031                 270   \n",
       "4           1971                 56          2027                 262   \n",
       "\n",
       "   eval_completion_tokens  eval_total_tokens  openai_cost  \n",
       "0                      47                305     0.000431  \n",
       "1                      58                346     0.000465  \n",
       "2                      49                343     0.000448  \n",
       "3                      52                322     0.000403  \n",
       "4                      60                322     0.000405  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval_rag_hybrid_gpt_4o_mini_stats.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc4972e2-fe9d-41c7-ac8c-cf001d838d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_grafana_data(df_eval_rag_hybrid_gpt_4o_mini_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d72bae6-9831-4fd9-9210-b88cd4d88ff0",
   "metadata": {},
   "source": [
    "## GPT-40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef0f9a55-ada7-42ae-9114-2c32c271c727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-4o'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_4O_MODEL_NAME = 'gpt-4o'\n",
    "GPT_4O_MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84f9ceff-73ff-4760-ac29-4fb7cb42e915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/evaluation/rag/gpt-4o_hybrid'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EVAL_RAG_GPT_4O_HYBRID_DATA_DIR = f\"{EVAL_RAG_DATA_DIR}/{GPT_4O_MODEL_NAME}_hybrid\"\n",
    "EVAL_RAG_GPT_4O_HYBRID_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1609005a-fef4-463e-b54d-2a02eafea2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_rag_hybrid_gpt_4o_stats = pd.read_csv(\n",
    "    f\"{EVAL_RAG_GPT_4O_HYBRID_DATA_DIR}/rag-evaluation-stats.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91862c39-0e92-4921-a3c0-941d2ae111dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>model_used</th>\n",
       "      <th>response_time</th>\n",
       "      <th>relevance</th>\n",
       "      <th>relevance_explanation</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>eval_prompt_tokens</th>\n",
       "      <th>eval_completion_tokens</th>\n",
       "      <th>eval_total_tokens</th>\n",
       "      <th>openai_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is the Shrimp Cream Soup a hot dish or can it ...</td>\n",
       "      <td>The Shrimp Cream Soup is a hot dish. It takes ...</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>3.536518</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses both a...</td>\n",
       "      <td>1453</td>\n",
       "      <td>21</td>\n",
       "      <td>1474</td>\n",
       "      <td>230</td>\n",
       "      <td>64</td>\n",
       "      <td>294</td>\n",
       "      <td>0.005058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is it necessary to add the nutmeg mentioned in...</td>\n",
       "      <td>The nutmeg is mentioned as part of the instruc...</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>6.142909</td>\n",
       "      <td>PARTLY_RELEVANT</td>\n",
       "      <td>The generated answer addresses the question ab...</td>\n",
       "      <td>2253</td>\n",
       "      <td>85</td>\n",
       "      <td>2338</td>\n",
       "      <td>294</td>\n",
       "      <td>67</td>\n",
       "      <td>361</td>\n",
       "      <td>0.007888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How do I prevent the shortcrust pastry from pu...</td>\n",
       "      <td>To prevent the shortcrust pastry from puffing ...</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>3.306008</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "      <td>2145</td>\n",
       "      <td>43</td>\n",
       "      <td>2188</td>\n",
       "      <td>248</td>\n",
       "      <td>68</td>\n",
       "      <td>316</td>\n",
       "      <td>0.007092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In the Octopus Galician Style recipe, what's t...</td>\n",
       "      <td>In the Octopus Galician Style recipe, the best...</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>6.080312</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses both p...</td>\n",
       "      <td>2131</td>\n",
       "      <td>63</td>\n",
       "      <td>2194</td>\n",
       "      <td>272</td>\n",
       "      <td>63</td>\n",
       "      <td>335</td>\n",
       "      <td>0.007267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are some tips for serving the Chickpeas w...</td>\n",
       "      <td>To serve the Chickpeas with Prawns dish, you c...</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>5.282053</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer provides specific tips fo...</td>\n",
       "      <td>2044</td>\n",
       "      <td>143</td>\n",
       "      <td>2187</td>\n",
       "      <td>347</td>\n",
       "      <td>58</td>\n",
       "      <td>405</td>\n",
       "      <td>0.007987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>How can I prevent the filling from oozing out ...</td>\n",
       "      <td>To prevent the filling from oozing out while f...</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>4.468939</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "      <td>2110</td>\n",
       "      <td>76</td>\n",
       "      <td>2186</td>\n",
       "      <td>289</td>\n",
       "      <td>63</td>\n",
       "      <td>352</td>\n",
       "      <td>0.007387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>What is the recommended cooking time for the R...</td>\n",
       "      <td>The recommended cooking time for the Roasted P...</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>4.964379</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer suggests a cooking time o...</td>\n",
       "      <td>1773</td>\n",
       "      <td>29</td>\n",
       "      <td>1802</td>\n",
       "      <td>235</td>\n",
       "      <td>81</td>\n",
       "      <td>316</td>\n",
       "      <td>0.006120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>Should I add the choricero pepper paste before...</td>\n",
       "      <td>For the \"Mixed Paella,\" you should add the cho...</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>5.200654</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "      <td>2276</td>\n",
       "      <td>54</td>\n",
       "      <td>2330</td>\n",
       "      <td>259</td>\n",
       "      <td>67</td>\n",
       "      <td>326</td>\n",
       "      <td>0.007547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>Can I serve the Hake in Green Sauce dish cold ...</td>\n",
       "      <td>The Hake in Green Sauce dish is designed to be...</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>4.375126</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "      <td>1791</td>\n",
       "      <td>33</td>\n",
       "      <td>1824</td>\n",
       "      <td>236</td>\n",
       "      <td>50</td>\n",
       "      <td>286</td>\n",
       "      <td>0.005897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>Can I use ground meat instead of butifarra in ...</td>\n",
       "      <td>Yes, you can use ground meat instead of butifa...</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>4.262116</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "      <td>1689</td>\n",
       "      <td>193</td>\n",
       "      <td>1882</td>\n",
       "      <td>410</td>\n",
       "      <td>61</td>\n",
       "      <td>471</td>\n",
       "      <td>0.007788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0    Is the Shrimp Cream Soup a hot dish or can it ...   \n",
       "1    Is it necessary to add the nutmeg mentioned in...   \n",
       "2    How do I prevent the shortcrust pastry from pu...   \n",
       "3    In the Octopus Galician Style recipe, what's t...   \n",
       "4    What are some tips for serving the Chickpeas w...   \n",
       "..                                                 ...   \n",
       "695  How can I prevent the filling from oozing out ...   \n",
       "696  What is the recommended cooking time for the R...   \n",
       "697  Should I add the choricero pepper paste before...   \n",
       "698  Can I serve the Hake in Green Sauce dish cold ...   \n",
       "699  Can I use ground meat instead of butifarra in ...   \n",
       "\n",
       "                                                answer model_used  \\\n",
       "0    The Shrimp Cream Soup is a hot dish. It takes ...     gpt-4o   \n",
       "1    The nutmeg is mentioned as part of the instruc...     gpt-4o   \n",
       "2    To prevent the shortcrust pastry from puffing ...     gpt-4o   \n",
       "3    In the Octopus Galician Style recipe, the best...     gpt-4o   \n",
       "4    To serve the Chickpeas with Prawns dish, you c...     gpt-4o   \n",
       "..                                                 ...        ...   \n",
       "695  To prevent the filling from oozing out while f...     gpt-4o   \n",
       "696  The recommended cooking time for the Roasted P...     gpt-4o   \n",
       "697  For the \"Mixed Paella,\" you should add the cho...     gpt-4o   \n",
       "698  The Hake in Green Sauce dish is designed to be...     gpt-4o   \n",
       "699  Yes, you can use ground meat instead of butifa...     gpt-4o   \n",
       "\n",
       "     response_time        relevance  \\\n",
       "0         3.536518         RELEVANT   \n",
       "1         6.142909  PARTLY_RELEVANT   \n",
       "2         3.306008         RELEVANT   \n",
       "3         6.080312         RELEVANT   \n",
       "4         5.282053         RELEVANT   \n",
       "..             ...              ...   \n",
       "695       4.468939         RELEVANT   \n",
       "696       4.964379     NON_RELEVANT   \n",
       "697       5.200654         RELEVANT   \n",
       "698       4.375126         RELEVANT   \n",
       "699       4.262116         RELEVANT   \n",
       "\n",
       "                                 relevance_explanation  prompt_tokens  \\\n",
       "0    The generated answer directly addresses both a...           1453   \n",
       "1    The generated answer addresses the question ab...           2253   \n",
       "2    The generated answer directly addresses the qu...           2145   \n",
       "3    The generated answer directly addresses both p...           2131   \n",
       "4    The generated answer provides specific tips fo...           2044   \n",
       "..                                                 ...            ...   \n",
       "695  The generated answer directly addresses the qu...           2110   \n",
       "696  The generated answer suggests a cooking time o...           1773   \n",
       "697  The generated answer directly addresses the qu...           2276   \n",
       "698  The generated answer directly addresses the qu...           1791   \n",
       "699  The generated answer directly addresses the qu...           1689   \n",
       "\n",
       "     completion_tokens  total_tokens  eval_prompt_tokens  \\\n",
       "0                   21          1474                 230   \n",
       "1                   85          2338                 294   \n",
       "2                   43          2188                 248   \n",
       "3                   63          2194                 272   \n",
       "4                  143          2187                 347   \n",
       "..                 ...           ...                 ...   \n",
       "695                 76          2186                 289   \n",
       "696                 29          1802                 235   \n",
       "697                 54          2330                 259   \n",
       "698                 33          1824                 236   \n",
       "699                193          1882                 410   \n",
       "\n",
       "     eval_completion_tokens  eval_total_tokens  openai_cost  \n",
       "0                        64                294     0.005058  \n",
       "1                        67                361     0.007888  \n",
       "2                        68                316     0.007092  \n",
       "3                        63                335     0.007267  \n",
       "4                        58                405     0.007987  \n",
       "..                      ...                ...          ...  \n",
       "695                      63                352     0.007387  \n",
       "696                      81                316     0.006120  \n",
       "697                      67                326     0.007547  \n",
       "698                      50                286     0.005897  \n",
       "699                      61                471     0.007788  \n",
       "\n",
       "[700 rows x 13 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval_rag_hybrid_gpt_4o_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "344e948d-4457-4135-b7a8-64bce3569d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_grafana_data(df_eval_rag_hybrid_gpt_4o_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80603c77-f3bf-4c32-b6e4-496d5e5b50f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c2a50c-d694-49e8-bc7d-ec8add955bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
