{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc568a96-6a5d-4181-b1bb-85c739bd8f3a",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93855ca-e8da-4c32-9839-03829616ac4c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Hybrid\n",
    "\n",
    "https://www.elastic.co/search-labs/blog/improving-information-retrieval-elastic-stack-hybrid\n",
    "\n",
    "https://lazycoder.ro/posts/elasticsearch-hybrid-semantic-search-embeddings/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e105e9-d691-404b-a559-72e25334e1c0",
   "metadata": {},
   "source": [
    "# Check Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7268972b-5b3c-4fe7-a055-adb0e4fa9e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "am I in Colab? False\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  import google.colab\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "print(f\"am I in Colab? {IN_COLAB}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a046d4-a751-4a9e-bdb1-301446f349e0",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b32a5181-f9fc-4473-89c6-b311be6918a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "from time import time\n",
    "\n",
    "# Elasticsearch\n",
    "from elasticsearch import Elasticsearch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Model\n",
    "#from sentence_transformers import SentenceTransformer\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "#from langchain_core.embeddings import Embeddings\n",
    "\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_text_splitters import TokenTextSplitter\n",
    "\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Model\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.embeddings import Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4403807-316d-4209-a439-d9b227864eb9",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2a3779a-6b02-415b-bfae-4800048d7096",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "  # Colab\n",
    "  BASE_DIR = \".\"\n",
    "  BACKUPS_DATA_DIR   = \"/content/drive/MyDrive/Colab Notebooks/Dataclub/llm/data\"\n",
    "else:\n",
    "  # Local\n",
    "  BASE_DIR = \"..\"\n",
    "  BACKUPS_DATA_DIR   = \"../backups\"\n",
    "\n",
    "# Raw directory\n",
    "RAW_DATA_DIR               = f\"{BASE_DIR}/data/raw\"\n",
    "RAW_DOCS_DATA_DIR          = f\"{BASE_DIR}/data/raw/documents\"\n",
    "RAW_INFO_DATA_DIR          = f\"{BASE_DIR}/data/raw/info\"\n",
    "# Preprocessing\n",
    "PROCESSED_DATA_DIR         = f\"{BASE_DIR}/data/processed\"\n",
    "PROCESSED_DOCS_DATA_DIR    = f\"{BASE_DIR}/data/processed/documents\"\n",
    "# Indexing\n",
    "INDEXING_DATA_DIR          = f\"{BASE_DIR}/data/indexing\"\n",
    "INDEXING_DOCS_DATA_DIR     = f\"{BASE_DIR}/data/indexing/documents\"\n",
    "# Test directory\n",
    "TEST_DATA_DIR               = f\"{BASE_DIR}/data/test\"\n",
    "GROUND_TRUTH_DATA_DIR       = f\"{BASE_DIR}/data/test/ground_truth\"\n",
    "GROUND_TRUTH_DOCS_DATA_DIR  = f\"{BASE_DIR}/data/test/ground_truth/documents\"\n",
    "GROUND_TRUTH_GEN_DATA_DIR   = f\"{BASE_DIR}/data/test/ground_truth/generated\"\n",
    "# Test directory\n",
    "EVAL_DATA_DIR            = f\"{BASE_DIR}/data/evaluation\"\n",
    "EVAL_RETRIEVER_DATA_DIR  = f\"{BASE_DIR}/data/evaluation/retriever\"\n",
    "EVAL_RAG_DATA_DIR        = f\"{BASE_DIR}/data/evaluation/rag\"\n",
    "# Config Prompts Dir\n",
    "PROMPTS_CONFIG_DIR = f\"{BASE_DIR}/cooking_recipe_assistant/config/prompts\"\n",
    "\n",
    "# Raw Info\n",
    "PLAYLIST_INFO_PATH = f\"{RAW_INFO_DATA_DIR}/playlist_info.pkl\"\n",
    "VIDEO_PLAYLIST_MAP_PATH = f\"{RAW_INFO_DATA_DIR}/video_playlist_map.pkl\"\n",
    "\n",
    "# Ground-truth\n",
    "GROUND_TRUTH_PATH = f\"{GROUND_TRUTH_DATA_DIR}/ground-truth-retrieval.csv\"\n",
    "\n",
    "# Optimization\n",
    "REST_OPT_ES_BM25_PATH       = f\"{EVAL_RETRIEVER_DATA_DIR}/res-opt-es-bm25.json\"\n",
    "REST_OPT_ES_HYBRID_PATH     = f\"{EVAL_RETRIEVER_DATA_DIR}/res-opt-es-hybrid.json\"\n",
    "REST_OPT_ES_HYBRID_RRF_PATH = f\"{EVAL_RETRIEVER_DATA_DIR}/res-opt-es-hybrid-rrf.json\"\n",
    "\n",
    "# Make dirs if not exists\n",
    "if not os.path.exists(RAW_DATA_DIR):\n",
    "  print(\"Not exists dir: \", RAW_DATA_DIR)\n",
    "os.makedirs(RAW_DOCS_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(RAW_INFO_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(PROCESSED_DOCS_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(TEST_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(EVAL_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(BACKUPS_DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8f0275c-51ca-46b4-bead-7261d499bca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Agregar solo si no está ya en sys.path\n",
    "if BASE_DIR not in sys.path:\n",
    "    sys.path.append(BASE_DIR)\n",
    "\n",
    "# Ahora puedes importar tu módulo\n",
    "import cooking_recipe_assistant\n",
    "from cooking_recipe_assistant.commons.utils import (\n",
    "    read_pickle, \n",
    "    read_document, \n",
    "    read_text,\n",
    "    save_pickle, \n",
    "    save_document,\n",
    "    save_text\n",
    ")\n",
    "\n",
    "from cooking_recipe_assistant.evaluation.retrievers import evaluate\n",
    "from cooking_recipe_assistant.evaluation.optimization import run_hyperopt\n",
    "from cooking_recipe_assistant.rags.retrievers.es_bm25 import es_bm25_query\n",
    "from cooking_recipe_assistant.rags.retrievers.es_hybrid import es_hybrid_query\n",
    "from cooking_recipe_assistant.rags.retrievers.es_hybrid_rrf import es_hybrid_rrf_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8101fe2e-3c38-482a-af40-b23416390154",
   "metadata": {},
   "outputs": [],
   "source": [
    "ES_URL = \"http://localhost:9200\"\n",
    "INDEX_NAME = \"cooking-recipes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6410424-c4f7-449b-ab94-aa4873ee6506",
   "metadata": {},
   "outputs": [],
   "source": [
    "ES_CLIENT = Elasticsearch(hosts=[ES_URL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc981a13-5348-467f-99e6-2518f64f103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "MINILM_EMBEDDING_MODEL_NAME = 'all-MiniLM-L6-v2'\n",
    "#NMNET_EMBEDDING_MODEL_NAME = 'all-mpnet-base-v2'\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a7c7eb2-928e-48ba-b971-c113614959e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDINGS = HuggingFaceEmbeddings(model_name=MINILM_EMBEDDING_MODEL_NAME)\n",
    "#EMBEDDINGS = HuggingFaceEmbeddings(model_name=NMNET_EMBEDDING_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1853b35-f624-4761-af68-7ea3cc58529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM\n",
    "OLLAMA_URL = 'http://localhost:11434'\n",
    "PLAYLIST_TITLE = 'Imperial Stout'\n",
    "MODEL_NAME = 'gpt-4o-mini'\n",
    "MODEL_NAME = 'llama3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0082fa5b-f5b1-45c6-b9c2-ee9396c4033a",
   "metadata": {},
   "source": [
    "# Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "159c3c7d-7782-4617-89b9-483d4151a59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 68\n",
      "-rw-rw-r-- 1 aztleclan  109 oct 27 01:30 en_entry_template.txt\n",
      "-rw-rw-r-- 1 aztleclan 1380 oct 18 17:24 en_prompt_template_blocks.txt\n",
      "-rw-rw-r-- 1 aztleclan  831 oct 26 14:11 en_prompt_template_eval_rag_v1.txt\n",
      "-rw-rw-r-- 1 aztleclan  643 oct 25 17:50 en_prompt_template_eval_rag_v2.txt\n",
      "-rw-rw-r-- 1 aztleclan 1552 oct 18 20:04 en_prompt_template_extractions.txt\n",
      "-rw-rw-r-- 1 aztleclan 1612 oct 25 15:44 en_prompt_template_ground_truth_v1.txt\n",
      "-rw-rw-r-- 1 aztleclan 1534 oct 25 15:47 en_prompt_template_ground_truth_v2.txt\n",
      "-rw-rw-r-- 1 aztleclan 1175 oct 23 18:16 en_prompt_template_questions.txt\n",
      "-rw-rw-r-- 1 aztleclan  206 oct 24 16:33 en_prompt_template_rag_v1.txt\n",
      "-rw-rw-r-- 1 aztleclan  206 oct 26 15:25 en_prompt_template_rag_v2.txt\n",
      "-rw-rw-r-- 1 aztleclan  346 oct 25 02:00 en_prompt_template_system_assistent.txt\n",
      "-rw-rw-r-- 1 aztleclan 1529 oct 18 17:24 es_prompt_template_blocks.txt\n",
      "-rw-rw-r-- 1 aztleclan 1688 oct 18 23:07 es_prompt_template_extractions_v1.txt\n",
      "-rw-rw-r-- 1 aztleclan 1695 oct 18 22:59 es_prompt_template_extractions_v2.txt\n",
      "-rw-rw-r-- 1 aztleclan 1000 oct 16 01:09 prompt_template_divide_blocks.txt\n",
      "-rw-rw-r-- 1 aztleclan 2088 oct 18 17:21 prompt_template_transcript.txt\n",
      "-rw-rw-r-- 1 aztleclan 1834 oct 17 13:40 prompt_template_transcript_V2.txt\n"
     ]
    }
   ],
   "source": [
    "!ls -lg \"{PROMPTS_CONFIG_DIR}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dc6639b-2444-426f-8550-4548dc1a49be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meals: {meals}\n",
      "title: {title}\n",
      "ingredients: {ingredients}\n",
      "summary: {summary}\n",
      "instructions: {text}\n",
      "tips: {tips}\n"
     ]
    }
   ],
   "source": [
    "ENTRY_TEMPLATE = read_text(f\"{PROMPTS_CONFIG_DIR}/en_entry_template.txt\")\n",
    "print(ENTRY_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61fea6ba-1ca0-45e0-85ce-c24d6d968206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a cooking recipe asistente. Answer the QUESTION based on the CONTEXT of our recipe database. \n",
      "Use only the data in the CONTEXT when answering the QUESTION.\n",
      "\n",
      "CONTEXT: \n",
      "{context}\n",
      "\n",
      "QUESTION: {question}\n"
     ]
    }
   ],
   "source": [
    "TEMPLATE_RAG_V1 = read_text(f\"{PROMPTS_CONFIG_DIR}/en_prompt_template_rag_v1.txt\")\n",
    "print(TEMPLATE_RAG_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "284f459e-b35a-4cb9-96ef-66f0f6ef0bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a cooking recipe asistente. Answer the QUESTION based on the CONTEXT of our recipe database. \n",
      "Use only the data in the CONTEXT when answering the QUESTION.\n",
      "\n",
      "CONTEXT: \n",
      "{context}\n",
      "\n",
      "QUESTION: {question}\n"
     ]
    }
   ],
   "source": [
    "TEMPLATE_RAG_V2 = read_text(f\"{PROMPTS_CONFIG_DIR}/en_prompt_template_rag_v2.txt\")\n",
    "print(TEMPLATE_RAG_V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9e12d72-6232-4df1-8480-010d010c601c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert evaluator for a RAG system.\n",
      "Your task is to analyze the relevance of the generated answer to the given question.\n",
      "Based on the relevance of the generated answer, you will classify it\n",
      "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
      "\n",
      "Here is the data for evaluation:\n",
      "\n",
      "Question: {question}\n",
      "\n",
      "Generated Answer: {answer_llm}\n",
      "\n",
      "\n",
      "Please analyze the content and context of the generated answer in relation to the question. Provide the result in parsable JSON format without using code blocks. Do not generate solutions with additional text or json-style comments. Make sure the JSON is well-formed and has closing braces and brackets.\n",
      "Please follow the following format strictly:\n",
      "\n",
      "{{\n",
      "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
      "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
      "}}\n"
     ]
    }
   ],
   "source": [
    "TEMPLATE_LLM_JUDGE_V1 = read_text(f\"{PROMPTS_CONFIG_DIR}/en_prompt_template_eval_rag_v1.txt\")\n",
    "print(TEMPLATE_LLM_JUDGE_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd498a2a-9d29-4228-8505-bcc5b32304dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert evaluator for a RAG system.\n",
      "Your task is to analyze the relevance of the generated answer to the given question.\n",
      "Based on the relevance of the generated answer, you will classify it\n",
      "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
      "\n",
      "Here is the data for evaluation:\n",
      "\n",
      "Question: {question}\n",
      "Generated Answer: {answer_llm}\n",
      "\n",
      "Please analyze the content and context of the generated answer in relation to the question\n",
      "and provide your evaluation in parsable JSON without using code blocks:\n",
      "\n",
      "{{\n",
      "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
      "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
      "}}\n"
     ]
    }
   ],
   "source": [
    "TEMPLATE_LLM_JUDGE_V2 = read_text(f\"{PROMPTS_CONFIG_DIR}/en_prompt_template_eval_rag_v2.txt\")\n",
    "print(TEMPLATE_LLM_JUDGE_V2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8750846f-ea86-4e86-9092-43ec2cf9b7bc",
   "metadata": {},
   "source": [
    "# Check ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aff3e100-0b51-4296-a052-d9e764e5a7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"1ce7214a22c5\",\n",
      "    \"cluster_name\": \"docker-cluster\",\n",
      "    \"cluster_uuid\": \"wg43N1DqSdy9g9z_pOLIDQ\",\n",
      "    \"version\": {\n",
      "        \"number\": \"8.4.3\",\n",
      "        \"build_flavor\": \"default\",\n",
      "        \"build_type\": \"docker\",\n",
      "        \"build_hash\": \"42f05b9372a9a4a470db3b52817899b99a76ee73\",\n",
      "        \"build_date\": \"2022-10-04T07:17:24.662462378Z\",\n",
      "        \"build_snapshot\": false,\n",
      "        \"lucene_version\": \"9.3.0\",\n",
      "        \"minimum_wire_compatibility_version\": \"7.17.0\",\n",
      "        \"minimum_index_compatibility_version\": \"7.0.0\"\n",
      "    },\n",
      "    \"tagline\": \"You Know, for Search\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "info_es = ES_CLIENT.info()\n",
    "print(json.dumps(info_es.body, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b69fa59-ee95-4ceb-a6b4-773a7e8924e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"cooking-recipes\": {\n",
      "        \"aliases\": {},\n",
      "        \"mappings\": {\n",
      "            \"properties\": {\n",
      "                \"chunk_number\": {\n",
      "                    \"type\": \"integer\"\n",
      "                },\n",
      "                \"doc_id\": {\n",
      "                    \"type\": \"text\",\n",
      "                    \"fields\": {\n",
      "                        \"keyword\": {\n",
      "                            \"type\": \"keyword\",\n",
      "                            \"ignore_above\": 256\n",
      "                        }\n",
      "                    }\n",
      "                },\n",
      "                \"id\": {\n",
      "                    \"type\": \"text\"\n",
      "                },\n",
      "                \"ingredients\": {\n",
      "                    \"type\": \"keyword\"\n",
      "                },\n",
      "                \"meals\": {\n",
      "                    \"type\": \"keyword\"\n",
      "                },\n",
      "                \"summart_vector\": {\n",
      "                    \"type\": \"float\"\n",
      "                },\n",
      "                \"summary\": {\n",
      "                    \"type\": \"text\"\n",
      "                },\n",
      "                \"summary_vector\": {\n",
      "                    \"type\": \"dense_vector\",\n",
      "                    \"dims\": 384,\n",
      "                    \"index\": true,\n",
      "                    \"similarity\": \"cosine\"\n",
      "                },\n",
      "                \"text\": {\n",
      "                    \"type\": \"text\"\n",
      "                },\n",
      "                \"text_vector\": {\n",
      "                    \"type\": \"dense_vector\",\n",
      "                    \"dims\": 384,\n",
      "                    \"index\": true,\n",
      "                    \"similarity\": \"cosine\"\n",
      "                },\n",
      "                \"tips\": {\n",
      "                    \"type\": \"keyword\"\n",
      "                },\n",
      "                \"title\": {\n",
      "                    \"type\": \"text\"\n",
      "                },\n",
      "                \"title_vector\": {\n",
      "                    \"type\": \"dense_vector\",\n",
      "                    \"dims\": 384,\n",
      "                    \"index\": true,\n",
      "                    \"similarity\": \"cosine\"\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"settings\": {\n",
      "            \"index\": {\n",
      "                \"routing\": {\n",
      "                    \"allocation\": {\n",
      "                        \"include\": {\n",
      "                            \"_tier_preference\": \"data_content\"\n",
      "                        }\n",
      "                    }\n",
      "                },\n",
      "                \"number_of_shards\": \"1\",\n",
      "                \"provided_name\": \"cooking-recipes\",\n",
      "                \"creation_date\": \"1729698947472\",\n",
      "                \"number_of_replicas\": \"0\",\n",
      "                \"uuid\": \"xRPfDileSMin8UmdVwEoOQ\",\n",
      "                \"version\": {\n",
      "                    \"created\": \"8040399\"\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "if ES_CLIENT.indices.exists(index=INDEX_NAME):\n",
    "    info_indice = ES_CLIENT.indices.get(index=INDEX_NAME)\n",
    "    print(json.dumps(info_indice.body, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7192a4b1-0659-46e1-b0b4-6ee4dcd15585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"cooking-recipes\": {\n",
      "        \"settings\": {\n",
      "            \"index\": {\n",
      "                \"routing\": {\n",
      "                    \"allocation\": {\n",
      "                        \"include\": {\n",
      "                            \"_tier_preference\": \"data_content\"\n",
      "                        }\n",
      "                    }\n",
      "                },\n",
      "                \"number_of_shards\": \"1\",\n",
      "                \"provided_name\": \"cooking-recipes\",\n",
      "                \"creation_date\": \"1729698947472\",\n",
      "                \"number_of_replicas\": \"0\",\n",
      "                \"uuid\": \"xRPfDileSMin8UmdVwEoOQ\",\n",
      "                \"version\": {\n",
      "                    \"created\": \"8040399\"\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "if ES_CLIENT.indices.exists(index=INDEX_NAME):\n",
    "    settings = ES_CLIENT.indices.get_settings(index=INDEX_NAME)\n",
    "    print(json.dumps(settings.body, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59cddd52-485b-4ddd-b819-280989ca8855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Num:232\n"
     ]
    }
   ],
   "source": [
    "if ES_CLIENT.indices.exists(index=INDEX_NAME):\n",
    "    count = ES_CLIENT.count(index=INDEX_NAME)['count']\n",
    "    print(f\"Document Num:{count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55700969-87e5-4f48-80a3-4b68fe74ac05",
   "metadata": {},
   "source": [
    "# Check Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6eddc525-bb2c-4b55-8f9d-7c33c66e24d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> 384\n",
      "[-0.03306527063250542, -0.04929625988006592, 0.0011788202682510018, -0.052408862859010696, -0.037587061524391174, 0.025819718837738037, -0.03928518667817116, 0.05620156601071358, 0.0902889296412468, -0.052350059151649475]\n"
     ]
    }
   ],
   "source": [
    "text = \"LangChain is a framework for developing applications powered by language models.\"\n",
    "\n",
    "\n",
    "embedding_vector = EMBEDDINGS.embed_query(text)\n",
    "print(type(embedding_vector), len(embedding_vector))\n",
    "print(embedding_vector[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ff4580-32d1-49a4-8ef1-2c016a3af427",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96171ad3-3401-4d06-bf31-04756bc53286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_evaluation(\n",
    "    questions_str: str\n",
    "):\n",
    "    # Extraer los campos necesarios del documento JSON\n",
    "    formatted_json = None\n",
    "    try:\n",
    "        # Cleaning text\n",
    "        clean_text = re.sub(r'//.*', '', questions_str)\n",
    "        clean_text = re.sub('\\n', '', clean_text)\n",
    "        # Compilar la expresión regular \n",
    "        pattern = re.compile(r'\"Relevance\"\\s*:\\s*\"(.*?)\"\\s*,?\\s*\"Explanation\"\\s*:\\s*\"(.*?)\"(?:\\s*[\\},])?')\n",
    "        matches = pattern.findall(clean_text)\n",
    "        if matches:\n",
    "            relevance, explanation = matches[0]\n",
    "            formatted_json = {\n",
    "                \"relevance\": relevance,\n",
    "                \"explanation\": explanation\n",
    "            }\n",
    "    except Exception as e:\n",
    "        #print(f\"No se encontró contenido JSON. {text}\")\n",
    "        print(questions_str)\n",
    "        #print(\"The error is: \", e)\n",
    "        print(\"=\"*100)\n",
    "\n",
    "    return formatted_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dfa0a095-2a95-4118-bfb8-beebfacce1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_evaluations(\n",
    "    ground_truth_path: str,\n",
    "    gen_data_dir: str\n",
    "):\n",
    "    print(f\"[BUILD-EVALUATIONS] ground_truth_path : {ground_truth_path}\")\n",
    "    print(f\"[BUILD-EVALUATIONS] gen_data_dir      : {gen_data_dir}\")\n",
    "    #print(f\"[BUILD-EVALUATIONS] out_data_dir      : {out_data_dir}\")\n",
    "    generated_rag_dir = os.path.join(gen_data_dir, 'rag')\n",
    "    generated_llm_as_judge_dir = os.path.join(gen_data_dir, 'llm-as-judge')\n",
    "\n",
    "    stats = []\n",
    "    results = []\n",
    "    all_docs_with_errors = []\n",
    "    for root, _, files in os.walk(generated_rag_dir):\n",
    "        for filename in tqdm(files):\n",
    "            # Read document\n",
    "            if not filename.endswith(\".txt\"):\n",
    "                continue\n",
    "            \n",
    "            # Doc id\n",
    "            es_doc_id = os.path.splitext(filename)[0]\n",
    "            \n",
    "            # Read generated answer\n",
    "            generated_answer_path = os.path.join(root, filename)\n",
    "            generated_answer_str  = read_text(generated_answer_path)\n",
    "            \n",
    "            # Read generated judge\n",
    "            generated_judge_path = os.path.join(generated_llm_as_judge_dir, filename)\n",
    "            if not os.path.exists(generated_judge_path):\n",
    "                continue\n",
    "            generated_judge_str  = read_text(generated_judge_path)\n",
    "\n",
    "            # Parse generated judge\n",
    "            generated_judge_json = parse_evaluation(generated_judge_str)\n",
    "            if generated_judge_json is None:\n",
    "                all_docs_with_errors.append(es_doc_id)\n",
    "                continue\n",
    "\n",
    "            # Add result\n",
    "            [doc_id, chunk_number, q_number] = es_doc_id.split('@')\n",
    "            generated_judge_json['doc_id'] = doc_id\n",
    "            generated_judge_json['chunk_number'] = int(chunk_number)\n",
    "            generated_judge_json['number'] = int(q_number)\n",
    "            generated_judge_json['answer'] = generated_answer_str\n",
    "            results.append(generated_judge_json)\n",
    "            \n",
    "            # Read stats\n",
    "            stats_filename = f\"{es_doc_id}_stats.json\"\n",
    "            gen_answer_stats_path = os.path.join(root, stats_filename)\n",
    "            gen_judge_stats_path = os.path.join(generated_llm_as_judge_dir, stats_filename)\n",
    "            if os.path.exists(gen_answer_stats_path) and os.path.exists(gen_judge_stats_path):\n",
    "                gen_answer_stats = read_document(gen_answer_stats_path)\n",
    "                gen_judge_stats = read_document(gen_judge_stats_path)\n",
    "                answer_data = gen_answer_stats | gen_judge_stats\n",
    "                answer_data['doc_id'] = doc_id\n",
    "                answer_data['chunk_number'] = int(chunk_number)\n",
    "                answer_data['number'] = int(q_number)\n",
    "                answer_data[\"openai_cost\"] = answer_data[\"total_cost\"] + answer_data[\"eval_total_cost\"] \n",
    "                answer_data[\"response_time\"] = answer_data[\"response_time\"] + answer_data[\"eval_response_time\"]\n",
    "                answer_data.pop(\"eval_total_cost\")\n",
    "                answer_data.pop(\"eval_response_time\")\n",
    "                stats.append(answer_data)\n",
    "\n",
    "    # Generate results\n",
    "    print(f\"Generated questions with errors: {len(all_docs_with_errors)}\")\n",
    "    judge_df = pd.DataFrame(results)\n",
    "\n",
    "    # Realizar el join\n",
    "    questions_df = pd.read_csv(ground_truth_path)\n",
    "    evaluations_df = pd.merge(\n",
    "        questions_df, judge_df, on=['doc_id', 'chunk_number', 'number'], how='inner')\n",
    "\n",
    "    # Save results\n",
    "    evaluation_path = os.path.join(gen_data_dir, 'rag-evaluation.csv')\n",
    "    evaluations_df = evaluations_df[[\n",
    "        'id', 'doc_id', 'chunk_number', 'number', \n",
    "        'answer', 'question', 'relevance', 'explanation'\n",
    "    ]]\n",
    "    evaluations_df.to_csv(evaluation_path, index=False)\n",
    "\n",
    "    if len(stats) > 0:\n",
    "        stats_df = pd.DataFrame(stats)\n",
    "        print(f\"stats: {len(stats_df)}\")\n",
    "        eval_stats_df = pd.merge(\n",
    "            stats_df, evaluations_df, on=['doc_id', 'chunk_number', 'number'], how='inner'\n",
    "        )\n",
    "        eval_stats_df.rename(columns={'explanation': 'relevance_explanation'}, inplace=True)\n",
    "        eval_stats_df = eval_stats_df[[\n",
    "            \"question\", \"answer\", \"model_used\", \"response_time\", \"relevance\", \"relevance_explanation\",\n",
    "            \"prompt_tokens\", \"completion_tokens\", \"total_tokens\",\n",
    "            \"eval_prompt_tokens\", \"eval_completion_tokens\", \"eval_total_tokens\",\n",
    "            \"openai_cost\"\n",
    "        ]]\n",
    "        print(f\"eval_stats: {len(eval_stats_df)}\")\n",
    "        # Save results\n",
    "        eval_stats_path = os.path.join(gen_data_dir, 'rag-evaluation-stats.csv')\n",
    "        eval_stats_df.to_csv(eval_stats_path, index=False)\n",
    "        #stats_path = os.path.join(gen_data_dir, 'rag-evaluation-eval_stats.csv')\n",
    "        #stats_df.to_csv(stats_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12208021-410e-4c62-b5e5-d54f36a10590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_recipe_context(search_results, entry_template):\n",
    "    separator = \"\\n-----------\\n\"\n",
    "    formatted_docs = []\n",
    "    for doc in search_results:\n",
    "        doc['meals'] = ', '.join(doc['meals'])\n",
    "        doc['ingredients'] = ', '.join(doc['ingredients'])\n",
    "        doc['tips'] = ' '.join([t if t.endswith('.') else t + \".\" for t in doc['tips']])\n",
    "        formatted_doc = entry_template.format(**doc)\n",
    "        #context = context + ENTRY_TEMPLATE.format(**doc) + \"\\n\\n\"\n",
    "        #context = context + doc[\"text\"] + \"\\n\\n\"\n",
    "        formatted_docs.append(formatted_doc)\n",
    "    #return context.strip()\n",
    "    return separator.join(formatted_docs).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00a9b068-3e0b-40f6-8ea8-7508909ad76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_retriever(es_cnf:dict, entry_template):\n",
    "    # Create connection\n",
    "    es_url = es_cnf[\"url\"]\n",
    "    es_client = Elasticsearch(hosts=[es_url])\n",
    "\n",
    "    boosting = es_cnf[\"boosting\"]\n",
    "    index_name = es_cnf[\"index_name\"]\n",
    "    search_type = es_cnf['type']\n",
    "    if search_type == 'bm25':\n",
    "        print(f\"search_type: {search_type}\")\n",
    "        retriever = lambda query: build_recipe_context(\n",
    "            es_bm25_query(es_client, index_name, query, boosting),\n",
    "            entry_template\n",
    "        )\n",
    "    elif search_type == 'hybrid':\n",
    "        print(f\"search_type: {search_type}\")\n",
    "        embedding_model_name = es_cnf[\"embedding\"][\"model_name\"]\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "        vector_field = es_cnf[\"vector_field\"]\n",
    "        retriever = lambda query: build_recipe_context(\n",
    "            es_hybrid_query(es_client, index_name, query, embeddings, vector_field, boosting),\n",
    "            entry_template\n",
    "        )\n",
    "    elif search_type == 'hybrid':\n",
    "        print(f\"search_type: {search_type}\")\n",
    "        embedding_model_name = es_cnf[\"embedding\"][\"model_name\"]\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "        vector_field = es_cnf[\"vector_field\"]\n",
    "        retriever = lambda query: build_recipe_context(\n",
    "            es_hybrid_rrf_query(es_client, index_name, query, embeddings, vector_field, boosting),\n",
    "            entry_template\n",
    "        )\n",
    "    else:\n",
    "        raise Exception(f\"Not found model name: {search_type}\")\n",
    "    return retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5e0b51b-1e7d-45ff-a551-821384a20fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_llm(\n",
    "    model_name:str,\n",
    "):\n",
    "    # Build llm\n",
    "    if model_name.startswith(\"llama\"):\n",
    "        print(f\"model: {model_name}\")\n",
    "        llm = ChatOllama(model=model_name)\n",
    "    elif model_name.startswith(\"gpt\"):\n",
    "        print(f\"model: {model_name}\")\n",
    "        llm = ChatOpenAI(model_name=model_name)\n",
    "    else:\n",
    "        raise Exception(f\"Not found model name: {model_name}\")\n",
    "\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3318383-c967-4e1e-95f7-a8b036c54d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_eval(\n",
    "    model_name:str,\n",
    "    template:str\n",
    "):\n",
    "    # Create prompt\n",
    "    #prompt = ChatPromptTemplate.from_template(\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        template=template\n",
    "    )\n",
    "    \n",
    "    # Build llm\n",
    "    llm = build_llm(model_name)\n",
    "    \n",
    "    # Build chain\n",
    "    qa_chain = (\n",
    "          prompt \n",
    "        | llm \n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    return qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4cf23174-d58d-49a6-a022-d955d4d34008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rag(\n",
    "    model_name:str,\n",
    "    template:str,\n",
    "    retriever\n",
    "):\n",
    "    # Create prompt\n",
    "    #prompt = ChatPromptTemplate.from_template(\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        template=template\n",
    "    )\n",
    "    \n",
    "    # Build llm\n",
    "    llm = build_llm(model_name)\n",
    "    \n",
    "    # Build chain\n",
    "    qa_chain = (\n",
    "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "        | prompt \n",
    "        | llm \n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    return qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a3b535d-d816-407b-8e11-216a0595c3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rag_colab(\n",
    "    sample, \n",
    "    rag_chain,\n",
    "    eval_chain,\n",
    "    src_data_dir,\n",
    "    out_data_dir,\n",
    "):\n",
    "    print(f\"[EVAL-RAG] sample       : {len(sample)}\")\n",
    "    print(f\"[EVAL-RAG] src_data_dir : {src_data_dir}\")\n",
    "    print(f\"[EVAL-RAG] out_data_dir : {out_data_dir}\")\n",
    "    generated_rag_dir = os.path.join(out_data_dir, 'rag')\n",
    "    generated_llm_as_judge_dir = os.path.join(out_data_dir, 'llm-as-judge')\n",
    "    os.makedirs(generated_rag_dir, exist_ok=True)\n",
    "    os.makedirs(generated_llm_as_judge_dir, exist_ok=True)\n",
    "    evaluations = []\n",
    "    count_generated = 0\n",
    "    for record in tqdm(sample):\n",
    "        question = record['question']\n",
    "        doc_id = record['id']\n",
    "        question__num = record['number']\n",
    "        #print( f'{doc_id}#{question__num}')\n",
    "        eval_id = f'{doc_id}@{question__num:03d}'\n",
    "        # RAG\n",
    "        rag_answer_path = os.path.join(generated_rag_dir, f'{eval_id}.txt')\n",
    "        if not os.path.exists(rag_answer_path): \n",
    "            print( f'Generating RAG {eval_id}')\n",
    "            es_ctx_path = os.path.join(src_data_dir, f'{eval_id}_context.txt')\n",
    "            es_context = read_text(es_ctx_path)\n",
    "            answer_llm = rag_chain.invoke({\"question\": question, \"context\": es_context}) \n",
    "            # Save results\n",
    "            save_text(rag_answer_path, answer_llm)\n",
    "            count_generated += 1\n",
    "        else:\n",
    "            answer_llm = read_text(rag_answer_path)\n",
    "\n",
    "        # LLLM-as-judge\n",
    "        llm_as_judge_answer_path = os.path.join(generated_llm_as_judge_dir, f'{eval_id}.txt')\n",
    "        if not os.path.exists(llm_as_judge_answer_path):\n",
    "            print( f'Generating JUDGE {eval_id}')\n",
    "            evaluation = eval_chain.invoke({\"question\": question, \"answer_llm\": answer_llm})\n",
    "            # Save results\n",
    "            save_text(llm_as_judge_answer_path, evaluation)\n",
    "\n",
    "        # Stop\n",
    "        if (count_generated+1) % 100 == 0:\n",
    "            print(\"Stop generating questions...\")\n",
    "            break\n",
    "\n",
    "    # Save testset\n",
    "    #evaluations_df = build_evaluations(generated_llm_as_judge_dir)\n",
    "    #evaluation_path = os.path.join(out_data_dir, 'rag-evaluation.csv')\n",
    "    #evaluations_df.to_csv(evaluation_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77d74389-a3c1-4cd3-84e7-287882fd93c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rag(\n",
    "    sample, \n",
    "    model_name,\n",
    "    rag_chain,\n",
    "    eval_chain,\n",
    "    output_data_dir,\n",
    "):\n",
    "    print(f\"[EVAL-RAG] sample          : {len(sample)}\")\n",
    "    print(f\"[EVAL-RAG] model_name      : {model_name}\")\n",
    "    print(f\"[EVAL-RAG] output_data_dir : {output_data_dir}\")\n",
    "    generated_rag_dir = os.path.join(output_data_dir, 'rag')\n",
    "    generated_llm_as_judge_dir = os.path.join(output_data_dir, 'llm-as-judge')\n",
    "    os.makedirs(generated_rag_dir, exist_ok=True)\n",
    "    os.makedirs(generated_llm_as_judge_dir, exist_ok=True)\n",
    "    evaluations = []\n",
    "\n",
    "    for record in tqdm(sample):\n",
    "        question = record['question']\n",
    "        doc_id = record['id']\n",
    "        question__num = record['number']\n",
    "        #print( f'{doc_id}#{question__num}')\n",
    "        eval_id = f'{doc_id}@{question__num:03d}'\n",
    "        # RAG\n",
    "        rag_answer_path = os.path.join(generated_rag_dir, f'{eval_id}.txt')\n",
    "        rag_stats_path = os.path.join(generated_rag_dir, f'{eval_id}_stats.json')\n",
    "        if not os.path.exists(rag_answer_path):\n",
    "            token_stats = {}\n",
    "            t0 = time()\n",
    "            if model_name.startswith(\"gpt\"):\n",
    "                with get_openai_callback() as cb:\n",
    "                    answer_llm = rag_chain.invoke(question)\n",
    "                token_stats = {\n",
    "                    \"prompt_tokens\": cb.prompt_tokens,\n",
    "                    \"completion_tokens\": cb.completion_tokens,\n",
    "                    \"total_tokens\": cb.total_tokens,\n",
    "                    \"total_cost\": cb.total_cost\n",
    "                }\n",
    "            else:\n",
    "                answer_llm = rag_chain.invoke(question)\n",
    "            t1 = time()\n",
    "            t_gen = t1 - t0\n",
    "            token_stats[\"model_used\"] = model_name\n",
    "            token_stats[\"response_time\"] = t_gen\n",
    "            # Save results\n",
    "            save_text(rag_answer_path, answer_llm)\n",
    "            save_document(rag_stats_path, token_stats)\n",
    "        else:\n",
    "            answer_llm = read_text(rag_answer_path)\n",
    "\n",
    "        # LLLM-as-judge\n",
    "        llm_as_judge_answer_path = os.path.join(generated_llm_as_judge_dir, f'{eval_id}.txt')\n",
    "        llm_as_judge_stats_path = os.path.join(generated_llm_as_judge_dir, f'{eval_id}_stats.json')\n",
    "        if not os.path.exists(llm_as_judge_answer_path):\n",
    "            eval_token_stats = {}\n",
    "            t0 = time()\n",
    "            if model_name.startswith(\"gpt\"):\n",
    "                with get_openai_callback() as cb:\n",
    "                    evaluation = eval_chain.invoke({\"question\": question, \"answer_llm\": answer_llm})\n",
    "                eval_token_stats = {\n",
    "                    \"eval_prompt_tokens\": cb.prompt_tokens,\n",
    "                    \"eval_completion_tokens\": cb.completion_tokens,\n",
    "                    \"eval_total_tokens\": cb.total_tokens,\n",
    "                    \"eval_total_cost\": cb.total_cost\n",
    "                }\n",
    "            else:\n",
    "                evaluation = eval_chain.invoke({\"question\": question, \"answer_llm\": answer_llm})\n",
    "            t1 = time()\n",
    "            t_eval = t1 - t0\n",
    "            eval_token_stats[\"model_used\"] = model_name\n",
    "            eval_token_stats[\"eval_response_time\"] = t_eval\n",
    "            # Save results\n",
    "            save_text(llm_as_judge_answer_path, evaluation)\n",
    "            save_document(llm_as_judge_stats_path, eval_token_stats)\n",
    "\n",
    "    # Save testset\n",
    "    #evaluations_df = build_evaluations(generated_llm_as_judge_dir)\n",
    "    #evaluation_path = os.path.join(output_data_dir, 'rag-evaluation.csv')\n",
    "    #evaluations_df.to_csv(evaluation_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4524ba-41d2-4f17-a2c8-b90c86cc4c3a",
   "metadata": {},
   "source": [
    "# Ground-truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28c46d8b-3f66-47f0-aaaf-c7656838266f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 aztleclan aztleclan 2,2K oct 12 22:44 playlist_info.pkl\n",
      "-rw-rw-r-- 1 aztleclan aztleclan  11K oct 12 22:44 video_playlist_map.pkl\n"
     ]
    }
   ],
   "source": [
    "!ls -lh '{RAW_DATA_DIR}' 2>/dev/null | grep pkl  2>/dev/null | head -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45f08af0-7a23-4cd9-a5f5-b6c1ebab2f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 aztleclan aztleclan 3,3K oct 23 17:55 086AnjxzAfg.json\n",
      "-rw-rw-r-- 1 aztleclan aztleclan 3,0K oct 23 17:55 0iZUayL1RQ0.json\n",
      "-rw-rw-r-- 1 aztleclan aztleclan 3,1K oct 23 17:55 0X7I-vr2oaM.json\n",
      "-rw-rw-r-- 1 aztleclan aztleclan 3,1K oct 23 17:55 1WAbPmolGqY.json\n",
      "-rw-rw-r-- 1 aztleclan aztleclan 3,3K oct 23 17:55 2CxQTUGD-5E.json\n"
     ]
    }
   ],
   "source": [
    "!ls -lh '{PROCESSED_DATA_DIR}/documents' 2>/dev/null | grep json 2>/dev/null | head -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "735b32ca-5ffc-4959-87f6-1a62b3a9f0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 aztleclan aztleclan 169K oct 26 23:21 ../data/test/ground_truth/ground-truth-retrieval.csv\n"
     ]
    }
   ],
   "source": [
    "!ls -lh \"{GROUND_TRUTH_PATH}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b36bfdf-9a10-437e-9ea9-0a0456f3378b",
   "metadata": {},
   "source": [
    "## Read Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72437f61-76c6-4525-8d0f-05c853d2e217",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ground_truth = pd.read_csv(GROUND_TRUTH_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e8dc4c1-5e87-4c43-aacd-9b077ca13c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>chunk_number</th>\n",
       "      <th>number</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>erjXeb0Hscw@000</td>\n",
       "      <td>erjXeb0Hscw</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>How do I achieve crispy and golden bacon for m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>erjXeb0Hscw@000</td>\n",
       "      <td>erjXeb0Hscw</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the recommended size of cheese cubes f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>erjXeb0Hscw@000</td>\n",
       "      <td>erjXeb0Hscw</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Can I cook the spaghetti longer than eight min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>erjXeb0Hscw@000</td>\n",
       "      <td>erjXeb0Hscw</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>How do I enhance the creaminess of the cheese ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>erjXeb0Hscw@000</td>\n",
       "      <td>erjXeb0Hscw</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Is my Creamy Spaghetti with Cheese and Bacon c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id       doc_id  chunk_number  number  \\\n",
       "0  erjXeb0Hscw@000  erjXeb0Hscw             0       1   \n",
       "1  erjXeb0Hscw@000  erjXeb0Hscw             0       2   \n",
       "2  erjXeb0Hscw@000  erjXeb0Hscw             0       3   \n",
       "3  erjXeb0Hscw@000  erjXeb0Hscw             0       4   \n",
       "4  erjXeb0Hscw@000  erjXeb0Hscw             0       5   \n",
       "\n",
       "                                            question  \n",
       "0  How do I achieve crispy and golden bacon for m...  \n",
       "1  What is the recommended size of cheese cubes f...  \n",
       "2  Can I cook the spaghetti longer than eight min...  \n",
       "3  How do I enhance the creaminess of the cheese ...  \n",
       "4  Is my Creamy Spaghetti with Cheese and Bacon c...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ground_truth.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cab8608b-86b8-4aa4-b976-8550c244e099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How do I achieve crispy and golden bacon for my Creamy Spaghetti with Cheese and Bacon?'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ground_truth.iloc[0].question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0df16e6c-f8e8-42f7-9d49-e317a2304039",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aztleclan/.local/share/virtualenvs/zoomcamp-llm-v-cF8mf4/lib/python3.10/site-packages/PIL/Image.py:122: RuntimeWarning: The _imaging extension was built for another version of Pillow or PIL:\n",
      "Core version: 11.0.0\n",
      "Pillow version: 10.4.0\n",
      "  warnings.warn(str(v), RuntimeWarning)\n",
      "[autoreload of PIL.Image failed: Traceback (most recent call last):\n",
      "  File \"/home/aztleclan/.local/share/virtualenvs/zoomcamp-llm-v-cF8mf4/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/aztleclan/.local/share/virtualenvs/zoomcamp-llm-v-cF8mf4/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/usr/lib/python3.10/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/home/aztleclan/.local/share/virtualenvs/zoomcamp-llm-v-cF8mf4/lib/python3.10/site-packages/PIL/Image.py\", line 108, in <module>\n",
      "    raise ImportError(msg)\n",
      "ImportError: The _imaging extension was built for another version of Pillow or PIL:\n",
      "Core version: 11.0.0\n",
      "Pillow version: 10.4.0\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'What is the recommended size of cheese cubes for the semi-cured sheep cheese, aged cheese, and cheddar cheese in this recipe?'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ground_truth.iloc[1].question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e88742-1935-44f3-acba-a883e9e1af3c",
   "metadata": {},
   "source": [
    "# Geneate prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a4c4646a-9285-4d4c-a241-93f86c85ce63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genarate_prompt_ctx(\n",
    "    ground_truth,\n",
    "    template:str,\n",
    "    retriever,\n",
    "    out_data_dir:str\n",
    "):\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        template=template\n",
    "    )\n",
    "    for r in tqdm(ground_truth):\n",
    "        es_doc_id = r[\"id\"]\n",
    "        question_id = r[\"number\"]\n",
    "        question = r[\"question\"]\n",
    "        #print(f\"{es_doc_id}@{question_id:03d}\")\n",
    "        question_ctx = retriever(question)\n",
    "        prompt_rag = prompt.format(question=question, context=question_ctx)\n",
    "        eval_id = f\"{es_doc_id}@{question_id:03d}\"\n",
    "        # Save ctx and prompt\n",
    "        prompt_rag_path = os.path.join(out_data_dir, f\"{eval_id}_prompt.txt\")\n",
    "        save_text(prompt_rag_path, prompt_rag)\n",
    "        ctx_rag_path = os.path.join(out_data_dir, f\"{eval_id}_context.txt\")\n",
    "        save_text(ctx_rag_path, question_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5e3a1809-e315-4dfb-a69c-2a97eb8d2e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 512K\n",
      "drwxr-xr-x 3 aztleclan aztleclan 4,0K oct 25 16:16 generated\n",
      "-rw-rw-r-- 1 aztleclan aztleclan 169K oct 26 23:21 ground-truth-retrieval.csv\n",
      "-rw-r--r-- 1 aztleclan aztleclan 167K oct 25 16:58 ground-truth-retrieval-ok.csv\n",
      "-rw-r--r-- 1 aztleclan aztleclan 167K oct 25 16:58 ground-truth-retrieval-OK.csv\n",
      "total 12K\n",
      "-rw-rw-r-- 1 aztleclan aztleclan 676 oct 26 23:00 res-opt-es-bm25.json\n",
      "-rw-rw-r-- 1 aztleclan aztleclan 723 oct 26 21:54 res-opt-es-hybrid.json\n",
      "-rw-rw-r-- 1 aztleclan aztleclan 724 oct 26 22:20 res-opt-es-hybrid-rrf.json\n"
     ]
    }
   ],
   "source": [
    "!ls -lh \"{GROUND_TRUTH_DATA_DIR}\"\n",
    "!ls -lh \"{EVAL_RETRIEVER_DATA_DIR}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566b72ce-c831-4cae-a53c-b5284f212c65",
   "metadata": {},
   "source": [
    "## BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c1a1ff57-63da-45a4-9e53-6f3660515559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.65 ms, sys: 108 μs, total: 4.76 ms\n",
      "Wall time: 4.73 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b204878f-6260-4076-833a-96617295c577",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLAMA_MODEL_NAME = 'llama3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f0ea512b-f31f-4edf-ba43-db5366a0063b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/evaluation/retriever/res-opt-es-bm25.json\n",
      "{\n",
      "    \"meals\": 3.3780065729545834,\n",
      "    \"title\": 2.350519748557916,\n",
      "    \"ingredients\": 1.8480562377707013,\n",
      "    \"summary\": 4.142904195381872,\n",
      "    \"text\": 3.8827414870597465,\n",
      "    \"tips\": 3.2750400070515573\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Retriever\n",
    "es_url = \"http://localhost:9200\"\n",
    "index_name = \"cooking-recipes\"\n",
    "es_client = Elasticsearch(hosts=[es_url])\n",
    "vector_field='text_vector'\n",
    "opt_es_bm25 = read_document(REST_OPT_ES_BM25_PATH)\n",
    "print(REST_OPT_ES_BM25_PATH)\n",
    "boosts_bm25 = opt_es_bm25['best_boosts']\n",
    "print(json.dumps(boosts_bm25, indent=4))\n",
    "\n",
    "retriever_bm25 = lambda query: es_retriever_bm25(\n",
    "        es_client,\n",
    "        index_name,\n",
    "        query,\n",
    "        boosts_bm25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f0d0e1c8-cddf-49c4-9ecb-b1074695609a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/evaluation/rag/llama3_bm25\n",
      "../data/evaluation/rag/llama3_bm25/prompts_rag\n"
     ]
    }
   ],
   "source": [
    "# Output dir\n",
    "EVAL_RAG_LLAMA3_BM25_DATA_DIR = f\"{EVAL_RAG_DATA_DIR}/{LLAMA_MODEL_NAME}_bm25\"\n",
    "EVAL_RAG_LLAMA3_BM25_PROMPTS_DATA_DIR = f\"{EVAL_RAG_LLAMA3_BM25_DATA_DIR}/prompts_rag\"\n",
    "print(EVAL_RAG_LLAMA3_BM25_DATA_DIR)\n",
    "print(EVAL_RAG_LLAMA3_BM25_PROMPTS_DATA_DIR)\n",
    "os.makedirs(EVAL_RAG_LLAMA3_BM25_PROMPTS_DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7402c29d-993e-4471-8a5f-27bf1161876a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbcdc60079f246c2a4ac8890c01b11b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "genarate_prompt_ctx(\n",
    "    ground_truth=ground_truth,\n",
    "    template=TEMPLATE_RAG_V1,\n",
    "    retriever=retriever_bm25,\n",
    "    out_data_dir=EVAL_RAG_LLAMA3_BM25_PROMPTS_DATA_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0ab36f0d-0d93-499c-9a17-0fb3ab144786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1160\n",
      "1160\n"
     ]
    }
   ],
   "source": [
    "!ls -lh \"{EVAL_RAG_LLAMA3_BM25_PROMPTS_DATA_DIR}\" 2>/dev/null | grep '.*\\_context\\.txt' | wc -l\n",
    "!ls -lh \"{EVAL_RAG_LLAMA3_BM25_PROMPTS_DATA_DIR}\" 2>/dev/null | grep '.*\\_prompt\\.txt' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "35565eba-ef00-4e92-a85c-a3fce5693bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 26M\n",
      "-rw-rw-r-- 1 aztleclan aztleclan 8,3K oct 26 23:35 086AnjxzAfg@000@001_context.txt\n",
      "-rw-rw-r-- 1 aztleclan aztleclan 8,6K oct 26 23:35 086AnjxzAfg@000@001_prompt.txt\n",
      "-rw-rw-r-- 1 aztleclan aztleclan 8,0K oct 26 23:35 086AnjxzAfg@000@002_context.txt\n",
      "-rw-rw-r-- 1 aztleclan aztleclan 8,3K oct 26 23:35 086AnjxzAfg@000@002_prompt.txt\n"
     ]
    }
   ],
   "source": [
    "!ls -lh \"{EVAL_RAG_LLAMA3_BM25_PROMPTS_DATA_DIR}\" 2>/dev/null | head -5\n",
    "#!cat \"{EVAL_RAG_LLAMA3_BM25_PROMPTS_DATA_DIR}/086AnjxzAfg@000@001_context.txt\"\n",
    "#!cat \"{EVAL_RAG_LLAMA3_BM25_PROMPTS_DATA_DIR}/086AnjxzAfg@000@001_prompt.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29a8566-42cd-4ebc-ba7c-9094985d898b",
   "metadata": {},
   "source": [
    "## Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b971d5c4-7242-4e62-9570-2d107664f269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/evaluation/retriever/res-opt-es-hybrid.json\n",
      "{\n",
      "    \"meals\": 1.3267880385949111,\n",
      "    \"title\": 1.8744388428292256,\n",
      "    \"ingredients\": 1.5107278257070114,\n",
      "    \"summary\": 3.3330549166389503,\n",
      "    \"text\": 2.9015143483052235,\n",
      "    \"tips\": 2.619409172670707,\n",
      "    \"vector_boost\": 0.8992024772398135\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Retriever\n",
    "es_url = \"http://localhost:9200\"\n",
    "index_name = \"cooking-recipes\"\n",
    "es_client = Elasticsearch(hosts=[es_url])\n",
    "embeddings=EMBEDDINGS\n",
    "vector_field='text_vector'\n",
    "print(REST_OPT_ES_HYBRID_PATH)\n",
    "opt_es_hybrid = read_document(REST_OPT_ES_HYBRID_PATH)\n",
    "boosts_hybrid = opt_es_hybrid['best_boosts']\n",
    "print(json.dumps(boosts_hybrid, indent=4))\n",
    "\n",
    "retriever_hydrid = lambda query: es_retriever_hybrid(\n",
    "        es_client,\n",
    "        index_name,\n",
    "        query,\n",
    "        embeddings,\n",
    "        vector_field,\n",
    "        boosts_hybrid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "26be255c-4399-4a2d-9a56-de7c368badbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/evaluation/rag/llama3_hybrid\n",
      "../data/evaluation/rag/llama3_hybrid/prompts_rag\n"
     ]
    }
   ],
   "source": [
    "# Output dir\n",
    "EVAL_RAG_LLAMA3_HYBRID_DATA_DIR = f\"{EVAL_RAG_DATA_DIR}/{LLAMA_MODEL_NAME}_hybrid\"\n",
    "EVAL_RAG_LLAMA3_HYBRID_PROMPTS_DATA_DIR = f\"{EVAL_RAG_LLAMA3_HYBRID_DATA_DIR}/prompts_rag\"\n",
    "print(EVAL_RAG_LLAMA3_HYBRID_DATA_DIR)\n",
    "print(EVAL_RAG_LLAMA3_HYBRID_PROMPTS_DATA_DIR)\n",
    "os.makedirs(EVAL_RAG_LLAMA3_HYBRID_PROMPTS_DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b06f59af-4df9-4b2c-8532-965f2453b94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d6cf905b2b41cb937fda441ff8fad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "genarate_prompt_ctx(\n",
    "    ground_truth=ground_truth,\n",
    "    template=TEMPLATE_RAG_V1,\n",
    "    retriever=retriever_hydrid,\n",
    "    out_data_dir=EVAL_RAG_LLAMA3_HYBRID_PROMPTS_DATA_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "445f1e1e-7536-4a04-84d7-cfe5d216e4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1160\n",
      "1160\n"
     ]
    }
   ],
   "source": [
    "!ls -lh \"{EVAL_RAG_LLAMA3_HYBRID_PROMPTS_DATA_DIR}\" 2>/dev/null | grep '.*\\_context\\.txt' | wc -l\n",
    "!ls -lh \"{EVAL_RAG_LLAMA3_HYBRID_PROMPTS_DATA_DIR}\" 2>/dev/null | grep '.*\\_prompt\\.txt' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "40eab47b-9e71-4c1d-8427-6b8824e8a066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 26M\n",
      "-rw-rw-r-- 1 aztleclan aztleclan 8,5K oct 26 18:09 086AnjxzAfg@000@001_context.txt\n",
      "-rw-rw-r-- 1 aztleclan aztleclan 8,8K oct 26 18:09 086AnjxzAfg@000@001_prompt.txt\n",
      "-rw-rw-r-- 1 aztleclan aztleclan 8,7K oct 26 18:09 086AnjxzAfg@000@002_context.txt\n",
      "-rw-rw-r-- 1 aztleclan aztleclan 9,0K oct 26 18:09 086AnjxzAfg@000@002_prompt.txt\n"
     ]
    }
   ],
   "source": [
    "!ls -lh \"{EVAL_RAG_LLAMA3_HYBRID_PROMPTS_DATA_DIR}\" 2>/dev/null | head -5\n",
    "#!cat \"{EVAL_RAG_LLAMA3_HYBRID_PROMPTS_DATA_DIR}/086AnjxzAfg@000@001_context.txt\"\n",
    "#!cat \"{EVAL_RAG_LLAMA3_HYBRID_PROMPTS_DATA_DIR}/086AnjxzAfg@000@001_prompt.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6ba426-8b62-43cc-bf06-b9d374ac0c07",
   "metadata": {},
   "source": [
    "## Hybrid RRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5c7cc70b-0472-47c3-a6e3-fa1335e145d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/evaluation/retriever/res-opt-es-hybrid-rrf.json\n",
      "{\n",
      "    \"meals\": 1.4671273591308425,\n",
      "    \"title\": 1.47987055694058,\n",
      "    \"ingredients\": 4.882772492268252,\n",
      "    \"summary\": 4.882702537681318,\n",
      "    \"text\": 4.368904374010877,\n",
      "    \"tips\": 1.2126808445885127,\n",
      "    \"vector_boost\": 0.10557689395629086\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Retriever\n",
    "es_url = \"http://localhost:9200\"\n",
    "index_name = \"cooking-recipes\"\n",
    "es_client = Elasticsearch(hosts=[es_url])\n",
    "embeddings=EMBEDDINGS\n",
    "vector_field='text_vector'\n",
    "print(REST_OPT_ES_HYBRID_RRF_PATH)\n",
    "opt_es_hybrid_rrf = read_document(REST_OPT_ES_HYBRID_RRF_PATH)\n",
    "boosts_hybrid_rrf = opt_es_hybrid_rrf['best_boosts']\n",
    "print(json.dumps(boosts_hybrid_rrf, indent=4))\n",
    "\n",
    "retriever_hydrid_rrf = lambda query: es_retriever_hybrid(\n",
    "        es_client,\n",
    "        index_name,\n",
    "        query,\n",
    "        embeddings,\n",
    "        vector_field,\n",
    "        boosts_hybrid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2f6aeb1e-ff07-4429-afb4-967a489f2332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/evaluation/rag/llama3_hybrid_rrf\n",
      "../data/evaluation/rag/llama3_hybrid_rrf/prompts_rag\n"
     ]
    }
   ],
   "source": [
    "# Output dir\n",
    "EVAL_RAG_LLAMA3_HYBRID_RRF_DATA_DIR = f\"{EVAL_RAG_DATA_DIR}/{LLAMA_MODEL_NAME}_hybrid_rrf\"\n",
    "EVAL_RAG_LLAMA3_HYBRID_RRF_PROMPTS_DATA_DIR = f\"{EVAL_RAG_LLAMA3_HYBRID_RRF_DATA_DIR}/prompts_rag\"\n",
    "print(EVAL_RAG_LLAMA3_HYBRID_RRF_DATA_DIR)\n",
    "print(EVAL_RAG_LLAMA3_HYBRID_RRF_PROMPTS_DATA_DIR)\n",
    "os.makedirs(EVAL_RAG_LLAMA3_HYBRID_RRF_PROMPTS_DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c0fd9ae3-dcec-4beb-81bc-e6ef44493eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f3f393aeecc4a10acd92cdcbe281f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "genarate_prompt_ctx(\n",
    "    ground_truth=ground_truth,\n",
    "    template=TEMPLATE_RAG_V1,\n",
    "    retriever=retriever_hydrid_rrf,\n",
    "    out_data_dir=EVAL_RAG_LLAMA3_HYBRID_RRF_PROMPTS_DATA_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e84d32e6-eafa-4d04-9dfb-eed174b9ea38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1160\n",
      "1160\n"
     ]
    }
   ],
   "source": [
    "!ls -lh \"{EVAL_RAG_LLAMA3_HYBRID_RRF_PROMPTS_DATA_DIR}\" 2>/dev/null | grep '.*\\_context\\.txt' | wc -l\n",
    "!ls -lh \"{EVAL_RAG_LLAMA3_HYBRID_RRF_PROMPTS_DATA_DIR}\" 2>/dev/null | grep '.*\\_prompt\\.txt' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4eb7f7d1-aec1-4fba-83f1-f40181094c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 26M\n",
      "-rw-rw-r-- 1 aztleclan aztleclan 8,3K oct 26 23:40 086AnjxzAfg@000@001_context.txt\n",
      "-rw-rw-r-- 1 aztleclan aztleclan 8,6K oct 26 23:40 086AnjxzAfg@000@001_prompt.txt\n",
      "-rw-rw-r-- 1 aztleclan aztleclan 8,5K oct 26 23:40 086AnjxzAfg@000@002_context.txt\n",
      "-rw-rw-r-- 1 aztleclan aztleclan 8,8K oct 26 23:40 086AnjxzAfg@000@002_prompt.txt\n"
     ]
    }
   ],
   "source": [
    "!ls -lh \"{EVAL_RAG_LLAMA3_HYBRID_RRF_PROMPTS_DATA_DIR}\" 2>/dev/null | head -5\n",
    "#!cat \"{EVAL_RAG_LLAMA3_HYBRID_RRF_PROMPTS_DATA_DIR}/086AnjxzAfg@000@001_context.txt\"\n",
    "#!cat \"{EVAL_RAG_LLAMA3_HYBRID_RRF_PROMPTS_DATA_DIR}/086AnjxzAfg@000@001_prompt.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94cb3b8-0b52-42a2-a6cb-f6e6f7d59bcb",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "11837182-0db1-4d7f-8622-9b59a22895b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e113e932-5562-49e6-a54d-7f47391ad825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08df9506-868a-4434-9a40-7a32608d3246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 12K\n",
      "-rw-rw-r-- 1 aztleclan aztleclan 676 oct 26 23:00 res-opt-es-bm25.json\n",
      "-rw-rw-r-- 1 aztleclan aztleclan 723 oct 26 21:54 res-opt-es-hybrid.json\n",
      "-rw-rw-r-- 1 aztleclan aztleclan 724 oct 26 22:20 res-opt-es-hybrid-rrf.json\n"
     ]
    }
   ],
   "source": [
    "!ls -lh \"{EVAL_RETRIEVER_DATA_DIR}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae39bb52-d2b7-4e79-8096-050ae4c18f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 12K\n",
      "drwxrwxr-x 5 aztleclan aztleclan 4,0K oct 26 16:49 llama3_bm25\n",
      "drwxrwxr-x 5 aztleclan aztleclan 4,0K oct 27 17:16 llama3_hybrid\n",
      "drwxrwxr-x 3 aztleclan aztleclan 4,0K oct 26 18:08 llama3_hybrid_rrf\n"
     ]
    }
   ],
   "source": [
    "!ls -lh \"{EVAL_RAG_DATA_DIR}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c895c473-a463-40e1-898e-90908af76cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.03 ms, sys: 0 ns, total: 7.03 ms\n",
      "Wall time: 8.94 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Generate Data Dict\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2bde98-28d8-409b-b557-d628f57bf01e",
   "metadata": {},
   "source": [
    "## LLAMA3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "227f49ea-2077-48da-bbdf-c82665d44e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'llama3'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model name\n",
    "LLAMA_MODEL_NAME = 'llama3'\n",
    "LLAMA_MODEL_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89b735b-8732-45e8-9c13-3306d23a6b71",
   "metadata": {},
   "source": [
    "### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a7de1fa4-2a70-46d8-b0e6-c5ce378e7797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/evaluation/retriever/res-opt-es-hybrid.json\n",
      "{\n",
      "    \"method\": \"es_hybrid\",\n",
      "    \"best_boosts\": {\n",
      "        \"meals\": 1.3267880385949111,\n",
      "        \"title\": 1.8744388428292256,\n",
      "        \"ingredients\": 1.5107278257070114,\n",
      "        \"summary\": 3.3330549166389503,\n",
      "        \"text\": 2.9015143483052235,\n",
      "        \"tips\": 2.619409172670707,\n",
      "        \"vector_boost\": 0.8992024772398135\n",
      "    },\n",
      "    \"best_mrr\": 0.9194683908045982,\n",
      "    \"base_train_hit_rate\": 0.9181034482758621,\n",
      "    \"base_train_mrr\": 0.8942887931034492,\n",
      "    \"base_valid_hit_rate\": 0.9310344827586207,\n",
      "    \"base_valid_mrr\": 0.8894396551724137,\n",
      "    \"boost_train_hit_rate\": 0.9224137931034483,\n",
      "    \"boost_train_mrr\": 0.9194683908045982,\n",
      "    \"boost_valid_hit_rate\": 0.9396551724137931,\n",
      "    \"boost_valid_mrr\": 0.9077586206896553\n",
      "}\n",
      "search_type: hybrid\n"
     ]
    }
   ],
   "source": [
    "# Retriever\n",
    "vector_field='text_vector'\n",
    "print(REST_OPT_ES_HYBRID_PATH)\n",
    "opt_es_hybrid = read_document(REST_OPT_ES_HYBRID_PATH)\n",
    "print(json.dumps(opt_es_hybrid, indent=4))\n",
    "\n",
    "es_hybrid_conf = {\n",
    "  \"url\": ES_URL,\n",
    "  \"index_name\": INDEX_NAME,\n",
    "  \"type\": \"hybrid\",\n",
    "  \"vector_field\": 'text_vector',\n",
    "  \"boosting\": opt_es_hybrid['best_boosts'],\n",
    "  \"embedding\": {\"model_name\": MINILM_EMBEDDING_MODEL_NAME}\n",
    "}\n",
    "retriever_hydrid = build_retriever(es_hybrid_conf, ENTRY_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ce3b7eca-e91c-434c-b2c1-a777bb0a3d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/evaluation/rag/llama3_hybrid\n",
      "../data/evaluation/rag/llama3_hybrid/prompts_rag\n"
     ]
    }
   ],
   "source": [
    "# Output dir\n",
    "EVAL_RAG_LLAMA3_HYBRID_DATA_DIR = f\"{EVAL_RAG_DATA_DIR}/{LLAMA_MODEL_NAME}_hybrid\"\n",
    "EVAL_RAG_LLAMA3_HYBRID_PROMPTS_DATA_DIR = f\"{EVAL_RAG_LLAMA3_HYBRID_DATA_DIR}/prompts_rag\"\n",
    "print(EVAL_RAG_LLAMA3_HYBRID_DATA_DIR)\n",
    "print(EVAL_RAG_LLAMA3_HYBRID_PROMPTS_DATA_DIR)\n",
    "os.makedirs(EVAL_RAG_LLAMA3_HYBRID_PROMPTS_DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "178f5500-8de9-4334-9ad5-d3cc89d5d1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: llama3\n",
      "model: llama3\n"
     ]
    }
   ],
   "source": [
    "# RAG\n",
    "#rag_chain = build_rag(LLAMA_MODEL_NAME, TEMPLATE_RAG_V1, retriever_bm25)\n",
    "rag_chain = build_eval(LLAMA_MODEL_NAME, TEMPLATE_RAG_V1)\n",
    "\n",
    "# LLM-AS-JUDGE\n",
    "eval_chain = build_eval(LLAMA_MODEL_NAME, TEMPLATE_LLM_JUDGE_V1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd7db04-702e-4f47-a0bf-ee1233188883",
   "metadata": {},
   "source": [
    "### Run Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f280c110-26f6-4bb8-914a-4d536f39505c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EVAL-RAG] sample       : 1160\n",
      "[EVAL-RAG] src_data_dir : ../data/evaluation/rag/llama3_hybrid/prompts_rag\n",
      "[EVAL-RAG] out_data_dir : ../data/evaluation/rag/llama3_hybrid\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e850c68b9124a31aaeba80a0d5a3847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BUILD-EVALUATIONS] src_data_dir : ../data/evaluation/rag/llama3_hybrid/llm-as-judge\n",
      "../data/evaluation/rag/llama3_hybrid/llm-as-judge ../data/evaluation/rag/llama3_hybrid/llm-as-judge 1160\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f5b21ebcb394621956cb758a4b6c5db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated questions with errors: 0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate RAG Colab\n",
    "results = evaluate_rag_colab(\n",
    "    ground_truth, \n",
    "    rag_chain,\n",
    "    eval_chain,\n",
    "    EVAL_RAG_LLAMA3_HYBRID_PROMPTS_DATA_DIR,\n",
    "    EVAL_RAG_LLAMA3_HYBRID_DATA_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2b07e4be-9d63-4d80-98ef-7b245c1350d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EVAL-RAG] sample          : 1160\n",
      "[EVAL-RAG] model_name      : llama3\n",
      "[EVAL-RAG] output_data_dir : ../data/evaluation/rag/llama3_hybrid\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa8e87e4854475ab33a7b6aa6c7d912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59.5 ms, sys: 19.9 ms, total: 79.3 ms\n",
      "Wall time: 77.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Evaluate RAG\n",
    "results = evaluate_rag(\n",
    "    ground_truth, \n",
    "    LLAMA_MODEL_NAME,\n",
    "    rag_chain,\n",
    "    eval_chain,\n",
    "    EVAL_RAG_LLAMA3_HYBRID_DATA_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3a8424d8-4d12-46c8-9c3e-e103ef53d1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BUILD-EVALUATIONS] ground_truth_path : ../data/test/ground_truth/ground-truth-retrieval.csv\n",
      "[BUILD-EVALUATIONS] gen_data_dir      : ../data/evaluation/rag/llama3_hybrid\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93232220e5624bd9bcf8835ed6ba17b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated questions with errors: 0\n",
      "CPU times: user 111 ms, sys: 56.7 ms, total: 167 ms\n",
      "Wall time: 164 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Build evaluation\n",
    "build_evaluations(\n",
    "    ground_truth_path=GROUND_TRUTH_PATH,\n",
    "    gen_data_dir=EVAL_RAG_LLAMA3_HYBRID_DATA_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e63f21-c4ca-4416-9473-ed20dcf5e9e9",
   "metadata": {},
   "source": [
    "### Show Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "88d04487-f561-43cc-bfa7-2d2eaf86acaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1,3M\n",
      "drwxr-xr-x 2 aztleclan aztleclan  60K oct 27 02:55 llm-as-judge\n",
      "drwxrwxr-x 2 aztleclan aztleclan 128K oct 26 23:37 prompts_rag\n",
      "drwxr-xr-x 2 aztleclan aztleclan  60K oct 27 02:55 rag\n",
      "-rw-r--r-- 1 aztleclan aztleclan 1,1M oct 28 01:10 rag-evaluation.csv\n"
     ]
    }
   ],
   "source": [
    "!ls -lh \"{EVAL_RAG_LLAMA3_HYBRID_DATA_DIR}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7cd44b11-51c0-4bec-86a2-2b9a1299c46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_rag_hybrid_llam3 = pd.read_csv(f\"{EVAL_RAG_LLAMA3_HYBRID_DATA_DIR}/rag-evaluation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f5dae553-39d3-408d-9fab-4e7c66949a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>chunk_number</th>\n",
       "      <th>number</th>\n",
       "      <th>answer</th>\n",
       "      <th>question</th>\n",
       "      <th>relevance</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>erjXeb0Hscw@000</td>\n",
       "      <td>erjXeb0Hscw</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I think there may be some confusion! The recip...</td>\n",
       "      <td>How do I achieve crispy and golden bacon for m...</td>\n",
       "      <td>PARTLY_RELEVANT</td>\n",
       "      <td>The generated answer provides tips on how to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>erjXeb0Hscw@000</td>\n",
       "      <td>erjXeb0Hscw</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>According to the instructions in the Creamy Sp...</td>\n",
       "      <td>What is the recommended size of cheese cubes f...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>erjXeb0Hscw@000</td>\n",
       "      <td>erjXeb0Hscw</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>According to the recipe \"Creamy Spaghetti with...</td>\n",
       "      <td>Can I cook the spaghetti longer than eight min...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>erjXeb0Hscw@000</td>\n",
       "      <td>erjXeb0Hscw</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>A great question!\\n\\nTo enhance the creaminess...</td>\n",
       "      <td>How do I enhance the creaminess of the cheese ...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>erjXeb0Hscw@000</td>\n",
       "      <td>erjXeb0Hscw</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>According to the Tips for the \"Creamy Spaghett...</td>\n",
       "      <td>Is my Creamy Spaghetti with Cheese and Bacon c...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>9DIMOoVbyyE@000</td>\n",
       "      <td>9DIMOoVbyyE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I'm happy to help! However, I must point out t...</td>\n",
       "      <td>How do I prepare the pre-ferment for Roscón de...</td>\n",
       "      <td>PARTLY_RELEVANT</td>\n",
       "      <td>The generated answer does not directly provide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>9DIMOoVbyyE@000</td>\n",
       "      <td>9DIMOoVbyyE</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>I'm happy to help!\\n\\nHowever, I must point ou...</td>\n",
       "      <td>What type of flour should I use to make the st...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not address the spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>9DIMOoVbyyE@000</td>\n",
       "      <td>9DIMOoVbyyE</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>According to the context of our recipe databas...</td>\n",
       "      <td>In the instructions for Roscón de Reyes, it me...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>9DIMOoVbyyE@000</td>\n",
       "      <td>9DIMOoVbyyE</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>According to our recipe database, for Roscón d...</td>\n",
       "      <td>Can you clarify how to shape the dough into a ...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>9DIMOoVbyyE@000</td>\n",
       "      <td>9DIMOoVbyyE</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Based on the context of our recipe database, s...</td>\n",
       "      <td>What is the recommended baking temperature and...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1160 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id       doc_id  chunk_number  number  \\\n",
       "0     erjXeb0Hscw@000  erjXeb0Hscw             0       1   \n",
       "1     erjXeb0Hscw@000  erjXeb0Hscw             0       2   \n",
       "2     erjXeb0Hscw@000  erjXeb0Hscw             0       3   \n",
       "3     erjXeb0Hscw@000  erjXeb0Hscw             0       4   \n",
       "4     erjXeb0Hscw@000  erjXeb0Hscw             0       5   \n",
       "...               ...          ...           ...     ...   \n",
       "1155  9DIMOoVbyyE@000  9DIMOoVbyyE             0       1   \n",
       "1156  9DIMOoVbyyE@000  9DIMOoVbyyE             0       2   \n",
       "1157  9DIMOoVbyyE@000  9DIMOoVbyyE             0       3   \n",
       "1158  9DIMOoVbyyE@000  9DIMOoVbyyE             0       4   \n",
       "1159  9DIMOoVbyyE@000  9DIMOoVbyyE             0       5   \n",
       "\n",
       "                                                 answer  \\\n",
       "0     I think there may be some confusion! The recip...   \n",
       "1     According to the instructions in the Creamy Sp...   \n",
       "2     According to the recipe \"Creamy Spaghetti with...   \n",
       "3     A great question!\\n\\nTo enhance the creaminess...   \n",
       "4     According to the Tips for the \"Creamy Spaghett...   \n",
       "...                                                 ...   \n",
       "1155  I'm happy to help! However, I must point out t...   \n",
       "1156  I'm happy to help!\\n\\nHowever, I must point ou...   \n",
       "1157  According to the context of our recipe databas...   \n",
       "1158  According to our recipe database, for Roscón d...   \n",
       "1159  Based on the context of our recipe database, s...   \n",
       "\n",
       "                                               question        relevance  \\\n",
       "0     How do I achieve crispy and golden bacon for m...  PARTLY_RELEVANT   \n",
       "1     What is the recommended size of cheese cubes f...         RELEVANT   \n",
       "2     Can I cook the spaghetti longer than eight min...         RELEVANT   \n",
       "3     How do I enhance the creaminess of the cheese ...         RELEVANT   \n",
       "4     Is my Creamy Spaghetti with Cheese and Bacon c...         RELEVANT   \n",
       "...                                                 ...              ...   \n",
       "1155  How do I prepare the pre-ferment for Roscón de...  PARTLY_RELEVANT   \n",
       "1156  What type of flour should I use to make the st...     NON_RELEVANT   \n",
       "1157  In the instructions for Roscón de Reyes, it me...         RELEVANT   \n",
       "1158  Can you clarify how to shape the dough into a ...         RELEVANT   \n",
       "1159  What is the recommended baking temperature and...         RELEVANT   \n",
       "\n",
       "                                            explanation  \n",
       "0     The generated answer provides tips on how to a...  \n",
       "1     The generated answer directly addresses the qu...  \n",
       "2     The generated answer directly addresses the qu...  \n",
       "3     The generated answer directly addresses the qu...  \n",
       "4     The generated answer directly addresses the qu...  \n",
       "...                                                 ...  \n",
       "1155  The generated answer does not directly provide...  \n",
       "1156  The generated answer does not address the spec...  \n",
       "1157  The generated answer directly addresses the qu...  \n",
       "1158  The generated answer directly addresses the qu...  \n",
       "1159  The generated answer directly addresses the qu...  \n",
       "\n",
       "[1160 rows x 8 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval_rag_hybrid_llam3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "321be2f5-5bf7-427b-8c21-f1f7b96b6d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>question</th>\n",
       "      <th>relevance</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I think there may be some confusion! The recip...</td>\n",
       "      <td>How do I achieve crispy and golden bacon for m...</td>\n",
       "      <td>PARTLY_RELEVANT</td>\n",
       "      <td>The generated answer provides tips on how to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>According to the instructions in the Creamy Sp...</td>\n",
       "      <td>What is the recommended size of cheese cubes f...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>According to the recipe \"Creamy Spaghetti with...</td>\n",
       "      <td>Can I cook the spaghetti longer than eight min...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A great question!\\n\\nTo enhance the creaminess...</td>\n",
       "      <td>How do I enhance the creaminess of the cheese ...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>According to the Tips for the \"Creamy Spaghett...</td>\n",
       "      <td>Is my Creamy Spaghetti with Cheese and Bacon c...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              answer  \\\n",
       "0  I think there may be some confusion! The recip...   \n",
       "1  According to the instructions in the Creamy Sp...   \n",
       "2  According to the recipe \"Creamy Spaghetti with...   \n",
       "3  A great question!\\n\\nTo enhance the creaminess...   \n",
       "4  According to the Tips for the \"Creamy Spaghett...   \n",
       "\n",
       "                                            question        relevance  \\\n",
       "0  How do I achieve crispy and golden bacon for m...  PARTLY_RELEVANT   \n",
       "1  What is the recommended size of cheese cubes f...         RELEVANT   \n",
       "2  Can I cook the spaghetti longer than eight min...         RELEVANT   \n",
       "3  How do I enhance the creaminess of the cheese ...         RELEVANT   \n",
       "4  Is my Creamy Spaghetti with Cheese and Bacon c...         RELEVANT   \n",
       "\n",
       "                                         explanation  \n",
       "0  The generated answer provides tips on how to a...  \n",
       "1  The generated answer directly addresses the qu...  \n",
       "2  The generated answer directly addresses the qu...  \n",
       "3  The generated answer directly addresses the qu...  \n",
       "4  The generated answer directly addresses the qu...  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval_rag_hybrid_llam3[[\"answer\", \"question\", \"relevance\", \"explanation\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c10a2868-a185-467a-b7c1-d835f3dd85ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           570\n",
       "NON_RELEVANT       367\n",
       "PARTLY_RELEVANT    223\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval_rag_hybrid_llam3.relevance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5d35b8f9-3625-4d33-8080-9c88102acdaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           0.491379\n",
       "NON_RELEVANT       0.316379\n",
       "PARTLY_RELEVANT    0.192241\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval_rag_hybrid_llam3.relevance.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c22b0c-c7ba-4164-9b7c-790ab277a76c",
   "metadata": {},
   "source": [
    "## gpt-4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1cd67dc0-f1d2-4af8-9038-a69adc08db05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-4o-mini'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model name\n",
    "GPT_4O_MINI_MODEL_NAME = 'gpt-4o-mini'\n",
    "GPT_4O_MINI_MODEL_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551e47c4-ddd5-4afc-8376-2989aa03564c",
   "metadata": {},
   "source": [
    "#### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c55961b0-eeb2-4f73-a7f6-d3c1e1e19a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/evaluation/retriever/res-opt-es-hybrid.json\n",
      "{\n",
      "    \"method\": \"es_hybrid\",\n",
      "    \"best_boosts\": {\n",
      "        \"meals\": 1.3267880385949111,\n",
      "        \"title\": 1.8744388428292256,\n",
      "        \"ingredients\": 1.5107278257070114,\n",
      "        \"summary\": 3.3330549166389503,\n",
      "        \"text\": 2.9015143483052235,\n",
      "        \"tips\": 2.619409172670707,\n",
      "        \"vector_boost\": 0.8992024772398135\n",
      "    },\n",
      "    \"best_mrr\": 0.9194683908045982,\n",
      "    \"base_train_hit_rate\": 0.9181034482758621,\n",
      "    \"base_train_mrr\": 0.8942887931034492,\n",
      "    \"base_valid_hit_rate\": 0.9310344827586207,\n",
      "    \"base_valid_mrr\": 0.8894396551724137,\n",
      "    \"boost_train_hit_rate\": 0.9224137931034483,\n",
      "    \"boost_train_mrr\": 0.9194683908045982,\n",
      "    \"boost_valid_hit_rate\": 0.9396551724137931,\n",
      "    \"boost_valid_mrr\": 0.9077586206896553\n",
      "}\n",
      "search_type: hybrid\n"
     ]
    }
   ],
   "source": [
    "# Retriever\n",
    "vector_field='text_vector'\n",
    "print(REST_OPT_ES_HYBRID_PATH)\n",
    "opt_es_hybrid = read_document(REST_OPT_ES_HYBRID_PATH)\n",
    "print(json.dumps(opt_es_hybrid, indent=4))\n",
    "\n",
    "es_hybrid_conf = {\n",
    "  \"url\": ES_URL,\n",
    "  \"index_name\": INDEX_NAME,\n",
    "  \"type\": \"hybrid\",\n",
    "  \"vector_field\": 'text_vector',\n",
    "  \"boosting\": opt_es_hybrid['best_boosts'],\n",
    "  \"embedding\": {\"model_name\": MINILM_EMBEDDING_MODEL_NAME}\n",
    "}\n",
    "retriever_hydrid = build_retriever(es_hybrid_conf, ENTRY_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0863a63f-1806-4d91-b282-e0eae804d7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/evaluation/rag/gpt-4o-mini_hybrid\n",
      "../data/evaluation/rag/gpt-4o-mini_hybrid/prompts_rag\n"
     ]
    }
   ],
   "source": [
    "# Output dir\n",
    "EVAL_RAG_GPT_4O_MINI_HYBRID_DATA_DIR = f\"{EVAL_RAG_DATA_DIR}/{GPT_4O_MINI_MODEL_NAME}_hybrid\"\n",
    "EVAL_RAG_GPT_4O_MINI_HYBRID_PROMPTS_DATA_DIR = f\"{EVAL_RAG_GPT_4O_MINI_HYBRID_DATA_DIR}/prompts_rag\"\n",
    "print(EVAL_RAG_GPT_4O_MINI_HYBRID_DATA_DIR)\n",
    "print(EVAL_RAG_GPT_4O_MINI_HYBRID_PROMPTS_DATA_DIR)\n",
    "os.makedirs(EVAL_RAG_GPT_4O_MINI_HYBRID_PROMPTS_DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "737965fa-8f29-4b5a-9574-43dfee2b6e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: gpt-4o-mini\n",
      "model: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "# RAG\n",
    "gpt_4o_mini_rag_chain = build_rag(GPT_4O_MINI_MODEL_NAME, TEMPLATE_RAG_V1, retriever_hydrid)\n",
    "#gpt_4o_mini_rag_chain = build_eval(LLAMA_MODEL_NAME, TEMPLATE_RAG_V1)\n",
    "\n",
    "# LLM-AS-JUDGE\n",
    "gpt_4o_mini_eval_chain = build_eval(GPT_4O_MINI_MODEL_NAME, TEMPLATE_LLM_JUDGE_V1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61fbf7f-78a8-44e4-9522-9e2ba8f7de03",
   "metadata": {},
   "source": [
    "### Run Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "3d4c63eb-809e-4d45-ae88-980636783368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EVAL-RAG] sample          : 1160\n",
      "[EVAL-RAG] output_data_dir : ../data/evaluation/rag/gpt-4o-mini_hybrid\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da6f8f5f839c423c8a9690c18e64697c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate RAG\n",
    "results = evaluate_rag(\n",
    "    ground_truth, \n",
    "    GPT_4O_MINI_MODEL_NAME,\n",
    "    gpt_4o_mini_rag_chain,\n",
    "    gpt_4o_mini_eval_chain,\n",
    "    EVAL_RAG_GPT_4O_MINI_HYBRID_DATA_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1886b128-37be-45d3-a3bd-5a9cc9b14755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BUILD-EVALUATIONS] ground_truth_path : ../data/test/ground_truth/ground-truth-retrieval.csv\n",
      "[BUILD-EVALUATIONS] gen_data_dir      : ../data/evaluation/rag/gpt-4o-mini_hybrid\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1115c48bcb554f29b78d00b655e1f8c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2320 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated questions with errors: 0\n",
      "stats: 1160\n",
      "eval_stats: 1160\n",
      "CPU times: user 327 ms, sys: 170 ms, total: 497 ms\n",
      "Wall time: 908 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Build evaluation\n",
    "build_evaluations(\n",
    "    ground_truth_path=GROUND_TRUTH_PATH,\n",
    "    gen_data_dir=EVAL_RAG_GPT_4O_MINI_HYBRID_DATA_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940ccca4-a0b7-44f1-a74e-8d5e5f6f54c1",
   "metadata": {},
   "source": [
    "### Show Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "df8db4fd-4fd4-4dce-a49d-e2add3f8ee56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1,9M\n",
      "drwxrwxr-x 2 aztleclan aztleclan 120K oct 27 23:16 llm-as-judge\n",
      "drwxrwxr-x 2 aztleclan aztleclan 4,0K oct 27 19:12 prompts_rag\n",
      "drwxrwxr-x 2 aztleclan aztleclan 120K oct 27 23:16 rag\n",
      "-rw-rw-r-- 1 aztleclan aztleclan 817K oct 28 01:07 rag-evaluation.csv\n",
      "-rw-rw-r-- 1 aztleclan aztleclan 863K oct 28 01:07 rag-evaluation-stats.csv\n"
     ]
    }
   ],
   "source": [
    "!ls -lh \"{EVAL_RAG_GPT_4O_MINI_HYBRID_DATA_DIR}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "17913da8-4692-4a1f-ad12-778f1656420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_rag_hybrid_gpt_4o_mini = pd.read_csv(f\"{EVAL_RAG_GPT_4O_MINI_HYBRID_DATA_DIR}/rag-evaluation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4644a370-5d1a-4399-bb0e-64208243a8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>chunk_number</th>\n",
       "      <th>number</th>\n",
       "      <th>answer</th>\n",
       "      <th>question</th>\n",
       "      <th>relevance</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>erjXeb0Hscw@000</td>\n",
       "      <td>erjXeb0Hscw</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>To achieve crispy and golden bacon for your Cr...</td>\n",
       "      <td>How do I achieve crispy and golden bacon for m...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer provides specific instruc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>erjXeb0Hscw@000</td>\n",
       "      <td>erjXeb0Hscw</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>The recommended size for the cheese cubes for ...</td>\n",
       "      <td>What is the recommended size of cheese cubes f...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>erjXeb0Hscw@000</td>\n",
       "      <td>erjXeb0Hscw</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes, you can cook the spaghetti longer than ei...</td>\n",
       "      <td>Can I cook the spaghetti longer than eight min...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>erjXeb0Hscw@000</td>\n",
       "      <td>erjXeb0Hscw</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>To enhance the creaminess of the cheese sauce ...</td>\n",
       "      <td>How do I enhance the creaminess of the cheese ...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>erjXeb0Hscw@000</td>\n",
       "      <td>erjXeb0Hscw</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>The Creamy Spaghetti with Cheese and Bacon is ...</td>\n",
       "      <td>Is my Creamy Spaghetti with Cheese and Bacon c...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>9DIMOoVbyyE@000</td>\n",
       "      <td>9DIMOoVbyyE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>To prepare the pre-ferment for Roscón de Reyes...</td>\n",
       "      <td>How do I prepare the pre-ferment for Roscón de...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer provides a clear method f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>9DIMOoVbyyE@000</td>\n",
       "      <td>9DIMOoVbyyE</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>You should use strong flour, which is typicall...</td>\n",
       "      <td>What type of flour should I use to make the st...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>9DIMOoVbyyE@000</td>\n",
       "      <td>9DIMOoVbyyE</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>To soften butter without melting it, you can f...</td>\n",
       "      <td>In the instructions for Roscón de Reyes, it me...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>9DIMOoVbyyE@000</td>\n",
       "      <td>9DIMOoVbyyE</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>To shape the dough for Roscón de Reyes into a ...</td>\n",
       "      <td>Can you clarify how to shape the dough into a ...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses both p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>9DIMOoVbyyE@000</td>\n",
       "      <td>9DIMOoVbyyE</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>The recommended baking temperature for Roscón ...</td>\n",
       "      <td>What is the recommended baking temperature and...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer provides the specific bak...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1160 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id       doc_id  chunk_number  number  \\\n",
       "0     erjXeb0Hscw@000  erjXeb0Hscw             0       1   \n",
       "1     erjXeb0Hscw@000  erjXeb0Hscw             0       2   \n",
       "2     erjXeb0Hscw@000  erjXeb0Hscw             0       3   \n",
       "3     erjXeb0Hscw@000  erjXeb0Hscw             0       4   \n",
       "4     erjXeb0Hscw@000  erjXeb0Hscw             0       5   \n",
       "...               ...          ...           ...     ...   \n",
       "1155  9DIMOoVbyyE@000  9DIMOoVbyyE             0       1   \n",
       "1156  9DIMOoVbyyE@000  9DIMOoVbyyE             0       2   \n",
       "1157  9DIMOoVbyyE@000  9DIMOoVbyyE             0       3   \n",
       "1158  9DIMOoVbyyE@000  9DIMOoVbyyE             0       4   \n",
       "1159  9DIMOoVbyyE@000  9DIMOoVbyyE             0       5   \n",
       "\n",
       "                                                 answer  \\\n",
       "0     To achieve crispy and golden bacon for your Cr...   \n",
       "1     The recommended size for the cheese cubes for ...   \n",
       "2     Yes, you can cook the spaghetti longer than ei...   \n",
       "3     To enhance the creaminess of the cheese sauce ...   \n",
       "4     The Creamy Spaghetti with Cheese and Bacon is ...   \n",
       "...                                                 ...   \n",
       "1155  To prepare the pre-ferment for Roscón de Reyes...   \n",
       "1156  You should use strong flour, which is typicall...   \n",
       "1157  To soften butter without melting it, you can f...   \n",
       "1158  To shape the dough for Roscón de Reyes into a ...   \n",
       "1159  The recommended baking temperature for Roscón ...   \n",
       "\n",
       "                                               question relevance  \\\n",
       "0     How do I achieve crispy and golden bacon for m...  RELEVANT   \n",
       "1     What is the recommended size of cheese cubes f...  RELEVANT   \n",
       "2     Can I cook the spaghetti longer than eight min...  RELEVANT   \n",
       "3     How do I enhance the creaminess of the cheese ...  RELEVANT   \n",
       "4     Is my Creamy Spaghetti with Cheese and Bacon c...  RELEVANT   \n",
       "...                                                 ...       ...   \n",
       "1155  How do I prepare the pre-ferment for Roscón de...  RELEVANT   \n",
       "1156  What type of flour should I use to make the st...  RELEVANT   \n",
       "1157  In the instructions for Roscón de Reyes, it me...  RELEVANT   \n",
       "1158  Can you clarify how to shape the dough into a ...  RELEVANT   \n",
       "1159  What is the recommended baking temperature and...  RELEVANT   \n",
       "\n",
       "                                            explanation  \n",
       "0     The generated answer provides specific instruc...  \n",
       "1     The generated answer directly addresses the qu...  \n",
       "2     The generated answer directly addresses the qu...  \n",
       "3     The generated answer directly addresses the qu...  \n",
       "4     The generated answer directly addresses the qu...  \n",
       "...                                                 ...  \n",
       "1155  The generated answer provides a clear method f...  \n",
       "1156  The generated answer directly addresses the qu...  \n",
       "1157  The generated answer directly addresses the qu...  \n",
       "1158  The generated answer directly addresses both p...  \n",
       "1159  The generated answer provides the specific bak...  \n",
       "\n",
       "[1160 rows x 8 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval_rag_hybrid_gpt_4o_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "febdcdfd-f203-448d-9bbc-9a0b85b84bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>question</th>\n",
       "      <th>relevance</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To achieve crispy and golden bacon for your Cr...</td>\n",
       "      <td>How do I achieve crispy and golden bacon for m...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer provides specific instruc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The recommended size for the cheese cubes for ...</td>\n",
       "      <td>What is the recommended size of cheese cubes f...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes, you can cook the spaghetti longer than ei...</td>\n",
       "      <td>Can I cook the spaghetti longer than eight min...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To enhance the creaminess of the cheese sauce ...</td>\n",
       "      <td>How do I enhance the creaminess of the cheese ...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Creamy Spaghetti with Cheese and Bacon is ...</td>\n",
       "      <td>Is my Creamy Spaghetti with Cheese and Bacon c...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              answer  \\\n",
       "0  To achieve crispy and golden bacon for your Cr...   \n",
       "1  The recommended size for the cheese cubes for ...   \n",
       "2  Yes, you can cook the spaghetti longer than ei...   \n",
       "3  To enhance the creaminess of the cheese sauce ...   \n",
       "4  The Creamy Spaghetti with Cheese and Bacon is ...   \n",
       "\n",
       "                                            question relevance  \\\n",
       "0  How do I achieve crispy and golden bacon for m...  RELEVANT   \n",
       "1  What is the recommended size of cheese cubes f...  RELEVANT   \n",
       "2  Can I cook the spaghetti longer than eight min...  RELEVANT   \n",
       "3  How do I enhance the creaminess of the cheese ...  RELEVANT   \n",
       "4  Is my Creamy Spaghetti with Cheese and Bacon c...  RELEVANT   \n",
       "\n",
       "                                         explanation  \n",
       "0  The generated answer provides specific instruc...  \n",
       "1  The generated answer directly addresses the qu...  \n",
       "2  The generated answer directly addresses the qu...  \n",
       "3  The generated answer directly addresses the qu...  \n",
       "4  The generated answer directly addresses the qu...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval_rag_hybrid_gpt_4o_mini[[\"answer\", \"question\", \"relevance\", \"explanation\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e66b109d-6cad-478b-9c7d-17ea8027ac6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           1023\n",
       "PARTLY_RELEVANT     116\n",
       "NON_RELEVANT         21\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval_rag_hybrid_gpt_4o_mini.relevance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8432dd07-ac96-4a78-82a3-8ef83c344239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           0.881897\n",
       "PARTLY_RELEVANT    0.100000\n",
       "NON_RELEVANT       0.018103\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval_rag_hybrid_gpt_4o_mini.relevance.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "273ebf25-4f4d-4cfe-b7a7-f75f7e61ba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_rag_hybrid_gpt_4o_mini_stats = pd.read_csv(\n",
    "    f\"{EVAL_RAG_GPT_4O_MINI_HYBRID_DATA_DIR}/rag-evaluation-stats.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aa9af241-9f04-4a4f-bcd3-2e0e0bf78a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>model_used</th>\n",
       "      <th>response_time</th>\n",
       "      <th>relevance</th>\n",
       "      <th>relevance_explanation</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>eval_prompt_tokens</th>\n",
       "      <th>eval_completion_tokens</th>\n",
       "      <th>eval_total_tokens</th>\n",
       "      <th>openai_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the recommended temperature and time t...</td>\n",
       "      <td>The recommended temperature to bake the rolled...</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>1.349952</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer provides the exact temper...</td>\n",
       "      <td>2254</td>\n",
       "      <td>43</td>\n",
       "      <td>2297</td>\n",
       "      <td>258</td>\n",
       "      <td>47</td>\n",
       "      <td>305</td>\n",
       "      <td>0.000431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What's the best way to achieve a slightly liqu...</td>\n",
       "      <td>To achieve a slightly liquid consistency for t...</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>1.939975</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "      <td>2267</td>\n",
       "      <td>78</td>\n",
       "      <td>2345</td>\n",
       "      <td>288</td>\n",
       "      <td>58</td>\n",
       "      <td>346</td>\n",
       "      <td>0.000465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can I adjust the cooking time of the millefeui...</td>\n",
       "      <td>The cooking time for the Eggplant, Tomato, and...</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>2.055440</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "      <td>2178</td>\n",
       "      <td>79</td>\n",
       "      <td>2257</td>\n",
       "      <td>294</td>\n",
       "      <td>49</td>\n",
       "      <td>343</td>\n",
       "      <td>0.000448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do I grease the mold for the Creamy Fried ...</td>\n",
       "      <td>To grease the mold for the Creamy Fried Milk d...</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>1.479998</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "      <td>1972</td>\n",
       "      <td>59</td>\n",
       "      <td>2031</td>\n",
       "      <td>270</td>\n",
       "      <td>52</td>\n",
       "      <td>322</td>\n",
       "      <td>0.000403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the ideal temperature and timing to ch...</td>\n",
       "      <td>The filled chicken in the Chicken Villaray rec...</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>1.629993</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer provides both the timing ...</td>\n",
       "      <td>1971</td>\n",
       "      <td>56</td>\n",
       "      <td>2027</td>\n",
       "      <td>262</td>\n",
       "      <td>60</td>\n",
       "      <td>322</td>\n",
       "      <td>0.000405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the recommended temperature and time t...   \n",
       "1  What's the best way to achieve a slightly liqu...   \n",
       "2  Can I adjust the cooking time of the millefeui...   \n",
       "3  How do I grease the mold for the Creamy Fried ...   \n",
       "4  What is the ideal temperature and timing to ch...   \n",
       "\n",
       "                                              answer   model_used  \\\n",
       "0  The recommended temperature to bake the rolled...  gpt-4o-mini   \n",
       "1  To achieve a slightly liquid consistency for t...  gpt-4o-mini   \n",
       "2  The cooking time for the Eggplant, Tomato, and...  gpt-4o-mini   \n",
       "3  To grease the mold for the Creamy Fried Milk d...  gpt-4o-mini   \n",
       "4  The filled chicken in the Chicken Villaray rec...  gpt-4o-mini   \n",
       "\n",
       "   response_time relevance                              relevance_explanation  \\\n",
       "0       1.349952  RELEVANT  The generated answer provides the exact temper...   \n",
       "1       1.939975  RELEVANT  The generated answer directly addresses the qu...   \n",
       "2       2.055440  RELEVANT  The generated answer directly addresses the qu...   \n",
       "3       1.479998  RELEVANT  The generated answer directly addresses the qu...   \n",
       "4       1.629993  RELEVANT  The generated answer provides both the timing ...   \n",
       "\n",
       "   prompt_tokens  completion_tokens  total_tokens  eval_prompt_tokens  \\\n",
       "0           2254                 43          2297                 258   \n",
       "1           2267                 78          2345                 288   \n",
       "2           2178                 79          2257                 294   \n",
       "3           1972                 59          2031                 270   \n",
       "4           1971                 56          2027                 262   \n",
       "\n",
       "   eval_completion_tokens  eval_total_tokens  openai_cost  \n",
       "0                      47                305     0.000431  \n",
       "1                      58                346     0.000465  \n",
       "2                      49                343     0.000448  \n",
       "3                      52                322     0.000403  \n",
       "4                      60                322     0.000405  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval_rag_hybrid_gpt_4o_mini_stats.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc7c0ad-de3d-4b28-905d-19c9bd26aef3",
   "metadata": {},
   "source": [
    "## gpt-4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4aceb88b-8076-4fa0-aef2-6f9f3e1ad09b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gpt-4o'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model name\n",
    "GPT_4O_MODEL_NAME = 'gpt-4o'\n",
    "GPT_4O_MODEL_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9dfd80-a0be-43d6-97ea-a8eaf3432ca5",
   "metadata": {},
   "source": [
    "### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7b83997-7140-403a-9caf-c62f2aa9378a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/evaluation/retriever/res-opt-es-hybrid.json\n",
      "{\n",
      "    \"method\": \"es_hybrid\",\n",
      "    \"best_boosts\": {\n",
      "        \"meals\": 1.3267880385949111,\n",
      "        \"title\": 1.8744388428292256,\n",
      "        \"ingredients\": 1.5107278257070114,\n",
      "        \"summary\": 3.3330549166389503,\n",
      "        \"text\": 2.9015143483052235,\n",
      "        \"tips\": 2.619409172670707,\n",
      "        \"vector_boost\": 0.8992024772398135\n",
      "    },\n",
      "    \"best_mrr\": 0.9194683908045982,\n",
      "    \"base_train_hit_rate\": 0.9181034482758621,\n",
      "    \"base_train_mrr\": 0.8942887931034492,\n",
      "    \"base_valid_hit_rate\": 0.9310344827586207,\n",
      "    \"base_valid_mrr\": 0.8894396551724137,\n",
      "    \"boost_train_hit_rate\": 0.9224137931034483,\n",
      "    \"boost_train_mrr\": 0.9194683908045982,\n",
      "    \"boost_valid_hit_rate\": 0.9396551724137931,\n",
      "    \"boost_valid_mrr\": 0.9077586206896553\n",
      "}\n",
      "search_type: hybrid\n"
     ]
    }
   ],
   "source": [
    "# Retriever\n",
    "vector_field='text_vector'\n",
    "print(REST_OPT_ES_HYBRID_PATH)\n",
    "opt_es_hybrid = read_document(REST_OPT_ES_HYBRID_PATH)\n",
    "print(json.dumps(opt_es_hybrid, indent=4))\n",
    "\n",
    "es_hybrid_conf = {\n",
    "  \"url\": ES_URL,\n",
    "  \"index_name\": INDEX_NAME,\n",
    "  \"type\": \"hybrid\",\n",
    "  \"vector_field\": 'text_vector',\n",
    "  \"boosting\": opt_es_hybrid['best_boosts'],\n",
    "  \"embedding\": {\"model_name\": MINILM_EMBEDDING_MODEL_NAME}\n",
    "}\n",
    "retriever_hydrid = build_retriever(es_hybrid_conf, ENTRY_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a64ff4dd-5eff-4f55-be58-2f9b7d23aacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/evaluation/rag/gpt-4o_hybrid\n",
      "../data/evaluation/rag/gpt-4o_hybrid/prompts_rag\n"
     ]
    }
   ],
   "source": [
    "# Output dir\n",
    "EVAL_RAG_GPT_4O_HYBRID_DATA_DIR = f\"{EVAL_RAG_DATA_DIR}/{GPT_4O_MODEL_NAME}_hybrid\"\n",
    "EVAL_RAG_GPT_4O_HYBRID_PROMPTS_DATA_DIR = f\"{EVAL_RAG_GPT_4O_HYBRID_DATA_DIR}/prompts_rag\"\n",
    "print(EVAL_RAG_GPT_4O_HYBRID_DATA_DIR)\n",
    "print(EVAL_RAG_GPT_4O_HYBRID_PROMPTS_DATA_DIR)\n",
    "os.makedirs(EVAL_RAG_GPT_4O_HYBRID_PROMPTS_DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a883e041-f07b-43b2-91d7-cd38a20315f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: gpt-4o\n",
      "model: gpt-4o\n"
     ]
    }
   ],
   "source": [
    "# RAG\n",
    "gpt_4o_rag_chain = build_rag(GPT_4O_MODEL_NAME, TEMPLATE_RAG_V1, retriever_hydrid)\n",
    "#gpt_4o_mini_rag_chain = build_eval(LLAMA_MODEL_NAME, TEMPLATE_RAG_V1)\n",
    "\n",
    "# LLM-AS-JUDGE\n",
    "gpt_4o_eval_chain = build_eval(GPT_4O_MODEL_NAME, TEMPLATE_LLM_JUDGE_V1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b84aebb-587f-4371-834b-6ce9b7de23f6",
   "metadata": {},
   "source": [
    "### Run Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7778ad8b-bf3e-42a0-a07c-1fd7168128af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EVAL-RAG] sample          : 700\n",
      "[EVAL-RAG] model_name      : gpt-4o\n",
      "[EVAL-RAG] output_data_dir : ../data/evaluation/rag/gpt-4o_hybrid\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c7ef43ed1b422191b96b3f463f8349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.4 ms, sys: 34.1 ms, total: 79.5 ms\n",
      "Wall time: 138 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Evaluate RAG\n",
    "results = evaluate_rag(\n",
    "    ground_truth[:700], \n",
    "    GPT_4O_MODEL_NAME,\n",
    "    gpt_4o_rag_chain,\n",
    "    gpt_4o_eval_chain,\n",
    "    EVAL_RAG_GPT_4O_HYBRID_DATA_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "66949ffa-7fff-4431-a272-81c1eaba2ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BUILD-EVALUATIONS] ground_truth_path : ../data/test/ground_truth/ground-truth-retrieval.csv\n",
      "[BUILD-EVALUATIONS] gen_data_dir      : ../data/evaluation/rag/gpt-4o_hybrid\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ceccdc5cb6343a699ce8b601c3bf0c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated questions with errors: 0\n",
      "stats: 700\n",
      "eval_stats: 700\n",
      "CPU times: user 238 ms, sys: 112 ms, total: 350 ms\n",
      "Wall time: 557 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Build evaluation\n",
    "build_evaluations(\n",
    "    ground_truth_path=GROUND_TRUTH_PATH,\n",
    "    gen_data_dir=EVAL_RAG_GPT_4O_HYBRID_DATA_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53f4200-e9d9-426a-b2c5-453fad8820ba",
   "metadata": {},
   "source": [
    "### Show Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8ab1bfb5-bd82-438d-8e9c-efb90ca91f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1,2M\n",
      "drwxrwxr-x 2 aztleclan aztleclan  72K oct 28 00:58 llm-as-judge\n",
      "drwxrwxr-x 2 aztleclan aztleclan 4,0K oct 27 23:56 prompts_rag\n",
      "drwxrwxr-x 2 aztleclan aztleclan  72K oct 28 00:58 rag\n",
      "-rw-rw-r-- 1 aztleclan aztleclan 511K oct 28 01:05 rag-evaluation.csv\n",
      "-rw-rw-r-- 1 aztleclan aztleclan 532K oct 28 01:05 rag-evaluation-stats.csv\n"
     ]
    }
   ],
   "source": [
    "!ls -lh \"{EVAL_RAG_GPT_4O_HYBRID_DATA_DIR}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c044e102-8eff-4808-8f5d-d24dce68e38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_rag_hybrid_gpt_4o = pd.read_csv(f\"{EVAL_RAG_GPT_4O_HYBRID_DATA_DIR}/rag-evaluation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1c5e28ad-41c9-475d-9aa5-a55aea84d6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>chunk_number</th>\n",
       "      <th>number</th>\n",
       "      <th>answer</th>\n",
       "      <th>question</th>\n",
       "      <th>relevance</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>erjXeb0Hscw@000</td>\n",
       "      <td>erjXeb0Hscw</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>To achieve crispy and golden bacon for your Cr...</td>\n",
       "      <td>How do I achieve crispy and golden bacon for m...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>erjXeb0Hscw@000</td>\n",
       "      <td>erjXeb0Hscw</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>The recommended size for the cheese cubes of s...</td>\n",
       "      <td>What is the recommended size of cheese cubes f...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>erjXeb0Hscw@000</td>\n",
       "      <td>erjXeb0Hscw</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes, you can cook the spaghetti longer than ei...</td>\n",
       "      <td>Can I cook the spaghetti longer than eight min...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>erjXeb0Hscw@000</td>\n",
       "      <td>erjXeb0Hscw</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>To enhance the creaminess of the cheese sauce ...</td>\n",
       "      <td>How do I enhance the creaminess of the cheese ...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>erjXeb0Hscw@000</td>\n",
       "      <td>erjXeb0Hscw</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>According to the Tips in the recipe for Creamy...</td>\n",
       "      <td>Is my Creamy Spaghetti with Cheese and Bacon c...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>zzNpW51VfpQ@000</td>\n",
       "      <td>zzNpW51VfpQ</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>To prepare the gazpacho, start by washing all ...</td>\n",
       "      <td>What steps should I take to prepare the gazpac...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>zzNpW51VfpQ@000</td>\n",
       "      <td>zzNpW51VfpQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>If your gazpacho is too thick, you can adjust ...</td>\n",
       "      <td>How do I know if my gazpacho is too thick and ...</td>\n",
       "      <td>PARTLY_RELEVANT</td>\n",
       "      <td>The answer provides a solution to adjust the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>zzNpW51VfpQ@000</td>\n",
       "      <td>zzNpW51VfpQ</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>To adjust the amount of vinegar in traditional...</td>\n",
       "      <td>In traditional Andalusian Gazpacho, how do I a...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer provides a clear and dire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>zzNpW51VfpQ@000</td>\n",
       "      <td>zzNpW51VfpQ</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes, you can garnish your Andalusian Gazpacho ...</td>\n",
       "      <td>Can I garnish my Andalusian Gazpacho with any ...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>zzNpW51VfpQ@000</td>\n",
       "      <td>zzNpW51VfpQ</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>The recommended way to serve Traditional Andal...</td>\n",
       "      <td>What's the recommended way to serve Traditiona...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id       doc_id  chunk_number  number  \\\n",
       "0    erjXeb0Hscw@000  erjXeb0Hscw             0       1   \n",
       "1    erjXeb0Hscw@000  erjXeb0Hscw             0       2   \n",
       "2    erjXeb0Hscw@000  erjXeb0Hscw             0       3   \n",
       "3    erjXeb0Hscw@000  erjXeb0Hscw             0       4   \n",
       "4    erjXeb0Hscw@000  erjXeb0Hscw             0       5   \n",
       "..               ...          ...           ...     ...   \n",
       "695  zzNpW51VfpQ@000  zzNpW51VfpQ             0       1   \n",
       "696  zzNpW51VfpQ@000  zzNpW51VfpQ             0       2   \n",
       "697  zzNpW51VfpQ@000  zzNpW51VfpQ             0       3   \n",
       "698  zzNpW51VfpQ@000  zzNpW51VfpQ             0       4   \n",
       "699  zzNpW51VfpQ@000  zzNpW51VfpQ             0       5   \n",
       "\n",
       "                                                answer  \\\n",
       "0    To achieve crispy and golden bacon for your Cr...   \n",
       "1    The recommended size for the cheese cubes of s...   \n",
       "2    Yes, you can cook the spaghetti longer than ei...   \n",
       "3    To enhance the creaminess of the cheese sauce ...   \n",
       "4    According to the Tips in the recipe for Creamy...   \n",
       "..                                                 ...   \n",
       "695  To prepare the gazpacho, start by washing all ...   \n",
       "696  If your gazpacho is too thick, you can adjust ...   \n",
       "697  To adjust the amount of vinegar in traditional...   \n",
       "698  Yes, you can garnish your Andalusian Gazpacho ...   \n",
       "699  The recommended way to serve Traditional Andal...   \n",
       "\n",
       "                                              question        relevance  \\\n",
       "0    How do I achieve crispy and golden bacon for m...         RELEVANT   \n",
       "1    What is the recommended size of cheese cubes f...         RELEVANT   \n",
       "2    Can I cook the spaghetti longer than eight min...         RELEVANT   \n",
       "3    How do I enhance the creaminess of the cheese ...         RELEVANT   \n",
       "4    Is my Creamy Spaghetti with Cheese and Bacon c...         RELEVANT   \n",
       "..                                                 ...              ...   \n",
       "695  What steps should I take to prepare the gazpac...         RELEVANT   \n",
       "696  How do I know if my gazpacho is too thick and ...  PARTLY_RELEVANT   \n",
       "697  In traditional Andalusian Gazpacho, how do I a...         RELEVANT   \n",
       "698  Can I garnish my Andalusian Gazpacho with any ...         RELEVANT   \n",
       "699  What's the recommended way to serve Traditiona...         RELEVANT   \n",
       "\n",
       "                                           explanation  \n",
       "0    The generated answer directly addresses the qu...  \n",
       "1    The generated answer directly addresses the qu...  \n",
       "2    The generated answer directly addresses the qu...  \n",
       "3    The generated answer directly addresses the qu...  \n",
       "4    The generated answer directly addresses the qu...  \n",
       "..                                                 ...  \n",
       "695  The generated answer directly addresses the qu...  \n",
       "696  The answer provides a solution to adjust the c...  \n",
       "697  The generated answer provides a clear and dire...  \n",
       "698  The generated answer directly addresses the qu...  \n",
       "699  The generated answer directly addresses the qu...  \n",
       "\n",
       "[700 rows x 8 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval_rag_hybrid_gpt_4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2b3d9d49-f468-472e-a8d4-b6dba739686f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>question</th>\n",
       "      <th>relevance</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To achieve crispy and golden bacon for your Cr...</td>\n",
       "      <td>How do I achieve crispy and golden bacon for m...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The recommended size for the cheese cubes of s...</td>\n",
       "      <td>What is the recommended size of cheese cubes f...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes, you can cook the spaghetti longer than ei...</td>\n",
       "      <td>Can I cook the spaghetti longer than eight min...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To enhance the creaminess of the cheese sauce ...</td>\n",
       "      <td>How do I enhance the creaminess of the cheese ...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>According to the Tips in the recipe for Creamy...</td>\n",
       "      <td>Is my Creamy Spaghetti with Cheese and Bacon c...</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              answer  \\\n",
       "0  To achieve crispy and golden bacon for your Cr...   \n",
       "1  The recommended size for the cheese cubes of s...   \n",
       "2  Yes, you can cook the spaghetti longer than ei...   \n",
       "3  To enhance the creaminess of the cheese sauce ...   \n",
       "4  According to the Tips in the recipe for Creamy...   \n",
       "\n",
       "                                            question relevance  \\\n",
       "0  How do I achieve crispy and golden bacon for m...  RELEVANT   \n",
       "1  What is the recommended size of cheese cubes f...  RELEVANT   \n",
       "2  Can I cook the spaghetti longer than eight min...  RELEVANT   \n",
       "3  How do I enhance the creaminess of the cheese ...  RELEVANT   \n",
       "4  Is my Creamy Spaghetti with Cheese and Bacon c...  RELEVANT   \n",
       "\n",
       "                                         explanation  \n",
       "0  The generated answer directly addresses the qu...  \n",
       "1  The generated answer directly addresses the qu...  \n",
       "2  The generated answer directly addresses the qu...  \n",
       "3  The generated answer directly addresses the qu...  \n",
       "4  The generated answer directly addresses the qu...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval_rag_hybrid_gpt_4o[[\"answer\", \"question\", \"relevance\", \"explanation\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1afe263e-6630-4e19-8def-099aaf3a8ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           544\n",
       "PARTLY_RELEVANT    143\n",
       "NON_RELEVANT        13\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval_rag_hybrid_gpt_4o.relevance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "917ea25c-b87a-44e2-9677-36f4b6724d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           0.777143\n",
       "PARTLY_RELEVANT    0.204286\n",
       "NON_RELEVANT       0.018571\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval_rag_hybrid_gpt_4o.relevance.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4f3aeec2-ea79-4bf4-8c11-a907c90cca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_rag_hybrid_gpt_4o_stats = pd.read_csv(\n",
    "    f\"{EVAL_RAG_GPT_4O_HYBRID_DATA_DIR}/rag-evaluation-stats.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "da13255b-c34d-455f-a5ab-8d00837fce06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.callbacks import get_openai_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "94b76e45-8e28-4d52-bf9c-11711d7d0073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>model_used</th>\n",
       "      <th>response_time</th>\n",
       "      <th>relevance</th>\n",
       "      <th>relevance_explanation</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>eval_prompt_tokens</th>\n",
       "      <th>eval_completion_tokens</th>\n",
       "      <th>eval_total_tokens</th>\n",
       "      <th>openai_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is the Shrimp Cream Soup a hot dish or can it ...</td>\n",
       "      <td>The Shrimp Cream Soup is a hot dish. It takes ...</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>3.536518</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses both a...</td>\n",
       "      <td>1453</td>\n",
       "      <td>21</td>\n",
       "      <td>1474</td>\n",
       "      <td>230</td>\n",
       "      <td>64</td>\n",
       "      <td>294</td>\n",
       "      <td>0.005058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is it necessary to add the nutmeg mentioned in...</td>\n",
       "      <td>The nutmeg is mentioned as part of the instruc...</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>6.142909</td>\n",
       "      <td>PARTLY_RELEVANT</td>\n",
       "      <td>The generated answer addresses the question ab...</td>\n",
       "      <td>2253</td>\n",
       "      <td>85</td>\n",
       "      <td>2338</td>\n",
       "      <td>294</td>\n",
       "      <td>67</td>\n",
       "      <td>361</td>\n",
       "      <td>0.007888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How do I prevent the shortcrust pastry from pu...</td>\n",
       "      <td>To prevent the shortcrust pastry from puffing ...</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>3.306008</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "      <td>2145</td>\n",
       "      <td>43</td>\n",
       "      <td>2188</td>\n",
       "      <td>248</td>\n",
       "      <td>68</td>\n",
       "      <td>316</td>\n",
       "      <td>0.007092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In the Octopus Galician Style recipe, what's t...</td>\n",
       "      <td>In the Octopus Galician Style recipe, the best...</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>6.080312</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses both p...</td>\n",
       "      <td>2131</td>\n",
       "      <td>63</td>\n",
       "      <td>2194</td>\n",
       "      <td>272</td>\n",
       "      <td>63</td>\n",
       "      <td>335</td>\n",
       "      <td>0.007267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are some tips for serving the Chickpeas w...</td>\n",
       "      <td>To serve the Chickpeas with Prawns dish, you c...</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>5.282053</td>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer provides specific tips fo...</td>\n",
       "      <td>2044</td>\n",
       "      <td>143</td>\n",
       "      <td>2187</td>\n",
       "      <td>347</td>\n",
       "      <td>58</td>\n",
       "      <td>405</td>\n",
       "      <td>0.007987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Is the Shrimp Cream Soup a hot dish or can it ...   \n",
       "1  Is it necessary to add the nutmeg mentioned in...   \n",
       "2  How do I prevent the shortcrust pastry from pu...   \n",
       "3  In the Octopus Galician Style recipe, what's t...   \n",
       "4  What are some tips for serving the Chickpeas w...   \n",
       "\n",
       "                                              answer model_used  \\\n",
       "0  The Shrimp Cream Soup is a hot dish. It takes ...     gpt-4o   \n",
       "1  The nutmeg is mentioned as part of the instruc...     gpt-4o   \n",
       "2  To prevent the shortcrust pastry from puffing ...     gpt-4o   \n",
       "3  In the Octopus Galician Style recipe, the best...     gpt-4o   \n",
       "4  To serve the Chickpeas with Prawns dish, you c...     gpt-4o   \n",
       "\n",
       "   response_time        relevance  \\\n",
       "0       3.536518         RELEVANT   \n",
       "1       6.142909  PARTLY_RELEVANT   \n",
       "2       3.306008         RELEVANT   \n",
       "3       6.080312         RELEVANT   \n",
       "4       5.282053         RELEVANT   \n",
       "\n",
       "                               relevance_explanation  prompt_tokens  \\\n",
       "0  The generated answer directly addresses both a...           1453   \n",
       "1  The generated answer addresses the question ab...           2253   \n",
       "2  The generated answer directly addresses the qu...           2145   \n",
       "3  The generated answer directly addresses both p...           2131   \n",
       "4  The generated answer provides specific tips fo...           2044   \n",
       "\n",
       "   completion_tokens  total_tokens  eval_prompt_tokens  \\\n",
       "0                 21          1474                 230   \n",
       "1                 85          2338                 294   \n",
       "2                 43          2188                 248   \n",
       "3                 63          2194                 272   \n",
       "4                143          2187                 347   \n",
       "\n",
       "   eval_completion_tokens  eval_total_tokens  openai_cost  \n",
       "0                      64                294     0.005058  \n",
       "1                      67                361     0.007888  \n",
       "2                      68                316     0.007092  \n",
       "3                      63                335     0.007267  \n",
       "4                      58                405     0.007987  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval_rag_hybrid_gpt_4o_stats.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
